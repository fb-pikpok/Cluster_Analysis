{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-16T01:36:05.780791Z",
     "start_time": "2024-12-16T01:36:05.722199Z"
    }
   },
   "source": [
    "# General modules\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from helper.data_preparation import load_json\n",
    "\n",
    "# Language models\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_key = openai_api_key\n",
    "client = openai.Client()\n",
    "\n",
    "chat_model_name = 'gpt-4o-mini'\n",
    "embed_model_name = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "# Paths\n",
    "root_dir = r'C:\\Users\\fbohm\\Desktop\\Projects\\DataScience\\cluster_analysis\\Data\\Steamapps'\n",
    "steam_title = 'Market'\n",
    "\n",
    "path_db_analysed = os.path.join(root_dir, steam_title, \"db_analysed.json\")\n",
    "path_db_embedded = os.path.join(root_dir, steam_title, \"db_embedded.json\")\n",
    "\n",
    "path_db_clustered = os.path.join(root_dir, steam_title, \"db_clustered.json\")\n",
    "path_db_named = os.path.join(root_dir, steam_title, \"db_named.json\")\n",
    "\n",
    "\n",
    "# my imports\n",
    "from helper.utils import *\n",
    "from helper.cluster_analysis import *\n",
    "\n",
    "configure_api(client, chat_model_name)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Random sample",
   "id": "d16d1f2df69bf0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T03:21:11.299331Z",
     "start_time": "2024-12-13T03:21:11.287593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample_for_embedding = os.path.join(root_dir, steam_title, \"sample_for_embedding.json\")\n",
    "\n",
    "# data = read_json(path_db_analysed)\n",
    "# sample_data = get_random_sample(data, 50, seed=42)\n",
    "# save_to_json(sample_data, sample_for_embedding)\n"
   ],
   "id": "1d6b2c0a9d333085",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load Offline Embedding Model",
   "id": "604711d0a91fabe1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "methode = \"mpnet\"\n",
    "# paraphrase-MiniLM-L6-v2\n",
    "# sentence-transformers/all-mpnet-base-v2\n",
    "# Snowflake/snowflake-arctic-embed-m\n",
    "# BAAI/bge-large-en-v1.5\n",
    "# nomic-ai/nomic-embed-text-v1\n",
    "model = SentenceTransformer('dunzhang/stella_en_1.5B_v5')"
   ],
   "id": "7f6c00b5d30cd68a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Offline Embbeding",
   "id": "ea65247963c2947f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import logging\n",
    "from helper.utils import *\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def get_embedding(text, model):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    embedding = model.encode(text)\n",
    "\n",
    "    if isinstance(embedding, np.ndarray):\n",
    "        embedding = embedding.tolist()\n",
    "\n",
    "        \n",
    "    return embedding\n",
    "\n",
    "\n",
    "def flatten_and_embed(json_data, model, embed_key=\"sentence\"):\n",
    "    flattened_data = []\n",
    "    counter = 0\n",
    "    \n",
    "    logger.info(f'Using {model} for embedding')\n",
    "    for entry in json_data:\n",
    "        # Extract common fields\n",
    "        common_fields = {key: value for key, value in entry.items() if key != \"topics\"}\n",
    "        \n",
    "        if \"topics\" in entry and isinstance(entry[\"topics\"], list):\n",
    "            for topic in entry[\"topics\"]:\n",
    "                # Combine common fields with topic-specific fields\n",
    "                flattened_entry = {**common_fields, **topic}\n",
    "\n",
    "                # Generate embedding for the sentence\n",
    "                if embed_key in topic:\n",
    "                    flattened_entry[\"embedding\"] = get_embedding(topic[embed_key], model=model)\n",
    "                    counter += 1\n",
    "                    if counter % 10 == 0:\n",
    "                        logger.info(f\"Processed {counter} entries\")\n",
    "                else:\n",
    "                    flattened_entry[\"embedding\"] = None\n",
    "                    logger.info(f\"No sentence found in entry: {entry.get('recommendationid', 'Unknown')}\")\n",
    "                # Append the flattened entry to the list\n",
    "                flattened_data.append(flattened_entry)\n",
    "        else:\n",
    "            logger.warning(f\"No topics found in entry: {entry.get('recommendationid', 'Unknown')}\")\n",
    "    \n",
    "    return flattened_data\n",
    "\n",
    "\n",
    "#Setup Parameters\n",
    "data = read_json(sample_for_embedding)\n",
    "embed_key = \"sentence\"\n",
    "\n",
    "# Process the data\n",
    "processed_data = flatten_and_embed(data, model, embed_key)\n",
    "\n",
    "# Save the processed data\n",
    "output_file = os.path.join(root_dir, steam_title, f\"{methode}_embedding.json\")\n",
    "\n",
    "save_df_as_json(processed_data, output_file)\n",
    "logger.info(\"Data flattening and embedding completed successfully.\")"
   ],
   "id": "7d0ba020facc691e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# OpenAI Embedding",
   "id": "bb25cb4a8aaf1644"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:27:03.088589Z",
     "start_time": "2024-12-16T03:26:32.646467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import openai\n",
    "import logging\n",
    "from helper.utils import *\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   embedding = client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "   return embedding\n",
    "\n",
    "\n",
    "def flatten_and_embed(json_data, embed_model_name=\"text-embedding-3-large\", embed_key=\"sentence\"):\n",
    "    \"\"\"\n",
    "    Flattens the topics in the JSON data and embeds the sentences.\n",
    "    Args:\n",
    "        json_data (list): List of JSON entries with nested topics.\n",
    "        embed_model_name (str): The OpenAI embedding model name.\n",
    "    Returns:\n",
    "        list: A flattened list of JSON entries with embeddings.\n",
    "    \"\"\"\n",
    "    flattened_data = []\n",
    "    counter = 0\n",
    "    \n",
    "    for entry in json_data:\n",
    "        # Extract common fields\n",
    "        common_fields = {key: value for key, value in entry.items() if key != \"topics\"}\n",
    "        \n",
    "        if \"topics\" in entry and isinstance(entry[\"topics\"], list):\n",
    "            for topic in entry[\"topics\"]:\n",
    "                # Combine common fields with topic-specific fields\n",
    "                flattened_entry = {**common_fields, **topic}\n",
    "                #print(flattened_entry)\n",
    "                # Generate embedding for the sentence\n",
    "                if embed_key in topic:\n",
    "                    flattened_entry[\"embedding\"] = get_embedding(topic[embed_key], model=embed_model_name)\n",
    "                    counter += 1\n",
    "                    if counter % 10 == 0:\n",
    "                        logger.info(f\"Processed {counter} entries\")\n",
    "                else:\n",
    "                    flattened_entry[\"embedding\"] = None\n",
    "                    logger.info(f\"No sentence found in entry: {entry.get('recommendationid', 'Unknown')}\")\n",
    "                # Append the flattened entry to the list\n",
    "                flattened_data.append(flattened_entry)\n",
    "        else:\n",
    "            logger.warning(f\"No topics found in entry: {entry.get('recommendationid', 'Unknown')}\")\n",
    "    \n",
    "    return flattened_data\n",
    "\n",
    "\n",
    "data = read_json(sample_for_embedding)\n",
    "\n",
    "# Process the data\n",
    "logger.info(\"Flattening and embedding data...\")\n",
    "processed_data = flatten_and_embed(data)\n",
    "\n",
    "# Save the processed data\n",
    "\n",
    "output_file = os.path.join(root_dir, steam_title, \"openai_embedding.json\")\n",
    "\n",
    "\n",
    "save_df_as_json(processed_data, output_file)\n",
    "\n",
    "logger.info(\"Data flattening and embedding completed successfully.\")\n"
   ],
   "id": "a27f57a9f7031c22",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 16:26:32,670 - INFO - Flattening and embedding data...\n",
      "2024-12-16 16:26:41,540 - INFO - Processed 10 entries\n",
      "2024-12-16 16:26:53,474 - INFO - Processed 20 entries\n",
      "2024-12-16 16:26:59,820 - INFO - Processed 30 entries\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[63], line 58\u001B[0m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;66;03m# Process the data\u001B[39;00m\n\u001B[0;32m     57\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFlattening and embedding data...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 58\u001B[0m processed_data \u001B[38;5;241m=\u001B[39m \u001B[43mflatten_and_embed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;66;03m# Save the processed data\u001B[39;00m\n\u001B[0;32m     62\u001B[0m output_file \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(root_dir, steam_title, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mopenai_embedding.json\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[63], line 39\u001B[0m, in \u001B[0;36mflatten_and_embed\u001B[1;34m(json_data, embed_model_name, embed_key)\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;66;03m#print(flattened_entry)\u001B[39;00m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;66;03m# Generate embedding for the sentence\u001B[39;00m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m embed_key \u001B[38;5;129;01min\u001B[39;00m topic:\n\u001B[1;32m---> 39\u001B[0m     flattened_entry[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124membedding\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mget_embedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtopic\u001B[49m\u001B[43m[\u001B[49m\u001B[43membed_key\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43membed_model_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     40\u001B[0m     counter \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     41\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m counter \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m10\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "Cell \u001B[1;32mIn[63], line 12\u001B[0m, in \u001B[0;36mget_embedding\u001B[1;34m(text, model)\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_embedding\u001B[39m(text, model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext-embedding-3-small\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m     11\u001B[0m    text \u001B[38;5;241m=\u001B[39m text\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 12\u001B[0m    embedding \u001B[38;5;241m=\u001B[39m \u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membeddings\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mdata[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39membedding\n\u001B[0;32m     13\u001B[0m    \u001B[38;5;28;01mreturn\u001B[39;00m embedding\n",
      "File \u001B[1;32m~\\Documents\\Venvironments\\Lib\\site-packages\\openai\\resources\\embeddings.py:124\u001B[0m, in \u001B[0;36mEmbeddings.create\u001B[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[0;32m    118\u001B[0m         embedding\u001B[38;5;241m.\u001B[39membedding \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mfrombuffer(  \u001B[38;5;66;03m# type: ignore[no-untyped-call]\u001B[39;00m\n\u001B[0;32m    119\u001B[0m             base64\u001B[38;5;241m.\u001B[39mb64decode(data), dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfloat32\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    120\u001B[0m         )\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[0;32m    122\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\n\u001B[1;32m--> 124\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    125\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/embeddings\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    126\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding_create_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEmbeddingCreateParams\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    127\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    128\u001B[0m \u001B[43m        \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    129\u001B[0m \u001B[43m        \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    130\u001B[0m \u001B[43m        \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    131\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    132\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpost_parser\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    133\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    134\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mCreateEmbeddingResponse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    135\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Venvironments\\Lib\\site-packages\\openai\\_base_client.py:1277\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[0;32m   1263\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(\n\u001B[0;32m   1264\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1265\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1272\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1273\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[0;32m   1274\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[0;32m   1275\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[0;32m   1276\u001B[0m     )\n\u001B[1;32m-> 1277\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\Documents\\Venvironments\\Lib\\site-packages\\openai\\_base_client.py:954\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[0;32m    951\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    952\u001B[0m     retries_taken \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m--> 954\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    955\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    956\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    957\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    958\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    959\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretries_taken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretries_taken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    960\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Venvironments\\Lib\\site-packages\\openai\\_base_client.py:990\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001B[0m\n\u001B[0;32m    987\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSending HTTP Request: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, request\u001B[38;5;241m.\u001B[39mmethod, request\u001B[38;5;241m.\u001B[39murl)\n\u001B[0;32m    989\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 990\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    991\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    992\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_should_stream_response_body\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    993\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    994\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    995\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m httpx\u001B[38;5;241m.\u001B[39mTimeoutException \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m    996\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEncountered httpx.TimeoutException\u001B[39m\u001B[38;5;124m\"\u001B[39m, exc_info\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32m~\\Documents\\Venvironments\\Lib\\site-packages\\httpx\\_client.py:914\u001B[0m, in \u001B[0;36mClient.send\u001B[1;34m(self, request, stream, auth, follow_redirects)\u001B[0m\n\u001B[0;32m    906\u001B[0m follow_redirects \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    907\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfollow_redirects\n\u001B[0;32m    908\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(follow_redirects, UseClientDefault)\n\u001B[0;32m    909\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m follow_redirects\n\u001B[0;32m    910\u001B[0m )\n\u001B[0;32m    912\u001B[0m auth \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_request_auth(request, auth)\n\u001B[1;32m--> 914\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_handling_auth\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    915\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    916\u001B[0m \u001B[43m    \u001B[49m\u001B[43mauth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    917\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    918\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhistory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    919\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    920\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    921\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m stream:\n",
      "File \u001B[1;32m~\\Documents\\Venvironments\\Lib\\site-packages\\httpx\\_client.py:942\u001B[0m, in \u001B[0;36mClient._send_handling_auth\u001B[1;34m(self, request, auth, follow_redirects, history)\u001B[0m\n\u001B[0;32m    939\u001B[0m request \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(auth_flow)\n\u001B[0;32m    941\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 942\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_handling_redirects\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    943\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    944\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    945\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhistory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhistory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    946\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    947\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    948\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Documents\\Venvironments\\Lib\\site-packages\\httpx\\_client.py:979\u001B[0m, in \u001B[0;36mClient._send_handling_redirects\u001B[1;34m(self, request, follow_redirects, history)\u001B[0m\n\u001B[0;32m    976\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_event_hooks[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrequest\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m    977\u001B[0m     hook(request)\n\u001B[1;32m--> 979\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_single_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    980\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    981\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_event_hooks[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresponse\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[1;32m~\\Documents\\Venvironments\\Lib\\site-packages\\httpx\\_client.py:1015\u001B[0m, in \u001B[0;36mClient._send_single_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m   1010\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m   1011\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAttempted to send an async request with a sync Client instance.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1012\u001B[0m     )\n\u001B[0;32m   1014\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request\u001B[38;5;241m=\u001B[39mrequest):\n\u001B[1;32m-> 1015\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mtransport\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1017\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response\u001B[38;5;241m.\u001B[39mstream, SyncByteStream)\n\u001B[0;32m   1019\u001B[0m response\u001B[38;5;241m.\u001B[39mrequest \u001B[38;5;241m=\u001B[39m request\n",
      "File \u001B[1;32m~\\Documents\\Venvironments\\Lib\\site-packages\\httpx\\_transports\\default.py:233\u001B[0m, in \u001B[0;36mHTTPTransport.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    220\u001B[0m req \u001B[38;5;241m=\u001B[39m httpcore\u001B[38;5;241m.\u001B[39mRequest(\n\u001B[0;32m    221\u001B[0m     method\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mmethod,\n\u001B[0;32m    222\u001B[0m     url\u001B[38;5;241m=\u001B[39mhttpcore\u001B[38;5;241m.\u001B[39mURL(\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    230\u001B[0m     extensions\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mextensions,\n\u001B[0;32m    231\u001B[0m )\n\u001B[0;32m    232\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m map_httpcore_exceptions():\n\u001B[1;32m--> 233\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_pool\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    235\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(resp\u001B[38;5;241m.\u001B[39mstream, typing\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[0;32m    237\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Response(\n\u001B[0;32m    238\u001B[0m     status_code\u001B[38;5;241m=\u001B[39mresp\u001B[38;5;241m.\u001B[39mstatus,\n\u001B[0;32m    239\u001B[0m     headers\u001B[38;5;241m=\u001B[39mresp\u001B[38;5;241m.\u001B[39mheaders,\n\u001B[0;32m    240\u001B[0m     stream\u001B[38;5;241m=\u001B[39mResponseStream(resp\u001B[38;5;241m.\u001B[39mstream),\n\u001B[0;32m    241\u001B[0m     extensions\u001B[38;5;241m=\u001B[39mresp\u001B[38;5;241m.\u001B[39mextensions,\n\u001B[0;32m    242\u001B[0m )\n",
      "File \u001B[1;32m~\\Documents\\Venvironments\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:216\u001B[0m, in \u001B[0;36mConnectionPool.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    213\u001B[0m         closing \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_assign_requests_to_connections()\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_connections(closing)\n\u001B[1;32m--> 216\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exc \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    218\u001B[0m \u001B[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001B[39;00m\n\u001B[0;32m    219\u001B[0m \u001B[38;5;66;03m# the point at which the response is closed.\u001B[39;00m\n\u001B[0;32m    220\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response\u001B[38;5;241m.\u001B[39mstream, Iterable)\n",
      "File \u001B[1;32m~\\Documents\\Venvironments\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:196\u001B[0m, in \u001B[0;36mConnectionPool.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    192\u001B[0m connection \u001B[38;5;241m=\u001B[39m pool_request\u001B[38;5;241m.\u001B[39mwait_for_connection(timeout\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[0;32m    194\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    195\u001B[0m     \u001B[38;5;66;03m# Send the request on the assigned connection.\u001B[39;00m\n\u001B[1;32m--> 196\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    197\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpool_request\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\n\u001B[0;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ConnectionNotAvailable:\n\u001B[0;32m    200\u001B[0m     \u001B[38;5;66;03m# In some cases a connection may initially be available to\u001B[39;00m\n\u001B[0;32m    201\u001B[0m     \u001B[38;5;66;03m# handle a request, but then become unavailable.\u001B[39;00m\n\u001B[0;32m    202\u001B[0m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m    203\u001B[0m     \u001B[38;5;66;03m# In this case we clear the connection and try again.\u001B[39;00m\n\u001B[0;32m    204\u001B[0m     pool_request\u001B[38;5;241m.\u001B[39mclear_connection()\n",
      "File \u001B[1;32m~\\Documents\\Venvironments\\Lib\\site-packages\\httpcore\\_sync\\connection.py:101\u001B[0m, in \u001B[0;36mHTTPConnection.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m     98\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connect_failed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     99\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exc\n\u001B[1;32m--> 101\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_connection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\Venvironments\\Lib\\site-packages\\httpcore\\_sync\\http11.py:143\u001B[0m, in \u001B[0;36mHTTP11Connection.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    141\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m Trace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresponse_closed\u001B[39m\u001B[38;5;124m\"\u001B[39m, logger, request) \u001B[38;5;28;01mas\u001B[39;00m trace:\n\u001B[0;32m    142\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_response_closed()\n\u001B[1;32m--> 143\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exc\n",
      "File \u001B[1;32m~\\Documents\\Venvironments\\Lib\\site-packages\\httpcore\\_sync\\http11.py:113\u001B[0m, in \u001B[0;36mHTTP11Connection.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    102\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m    104\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m Trace(\n\u001B[0;32m    105\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreceive_response_headers\u001B[39m\u001B[38;5;124m\"\u001B[39m, logger, request, kwargs\n\u001B[0;32m    106\u001B[0m ) \u001B[38;5;28;01mas\u001B[39;00m trace:\n\u001B[0;32m    107\u001B[0m     (\n\u001B[0;32m    108\u001B[0m         http_version,\n\u001B[0;32m    109\u001B[0m         status,\n\u001B[0;32m    110\u001B[0m         reason_phrase,\n\u001B[0;32m    111\u001B[0m         headers,\n\u001B[0;32m    112\u001B[0m         trailing_data,\n\u001B[1;32m--> 113\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_receive_response_headers\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    114\u001B[0m     trace\u001B[38;5;241m.\u001B[39mreturn_value \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    115\u001B[0m         http_version,\n\u001B[0;32m    116\u001B[0m         status,\n\u001B[0;32m    117\u001B[0m         reason_phrase,\n\u001B[0;32m    118\u001B[0m         headers,\n\u001B[0;32m    119\u001B[0m     )\n\u001B[0;32m    121\u001B[0m network_stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_network_stream\n",
      "File \u001B[1;32m~\\Documents\\Venvironments\\Lib\\site-packages\\httpcore\\_sync\\http11.py:186\u001B[0m, in \u001B[0;36mHTTP11Connection._receive_response_headers\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    183\u001B[0m timeout \u001B[38;5;241m=\u001B[39m timeouts\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mread\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    185\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 186\u001B[0m     event \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_receive_event\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    187\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(event, h11\u001B[38;5;241m.\u001B[39mResponse):\n\u001B[0;32m    188\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\Venvironments\\Lib\\site-packages\\httpcore\\_sync\\http11.py:224\u001B[0m, in \u001B[0;36mHTTP11Connection._receive_event\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    221\u001B[0m     event \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_h11_state\u001B[38;5;241m.\u001B[39mnext_event()\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m event \u001B[38;5;129;01mis\u001B[39;00m h11\u001B[38;5;241m.\u001B[39mNEED_DATA:\n\u001B[1;32m--> 224\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_network_stream\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    225\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mREAD_NUM_BYTES\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[0;32m    226\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    228\u001B[0m     \u001B[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001B[39;00m\n\u001B[0;32m    229\u001B[0m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m    230\u001B[0m     \u001B[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    234\u001B[0m     \u001B[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001B[39;00m\n\u001B[0;32m    235\u001B[0m     \u001B[38;5;66;03m# it as a ConnectError.\u001B[39;00m\n\u001B[0;32m    236\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;241m==\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_h11_state\u001B[38;5;241m.\u001B[39mtheir_state \u001B[38;5;241m==\u001B[39m h11\u001B[38;5;241m.\u001B[39mSEND_RESPONSE:\n",
      "File \u001B[1;32m~\\Documents\\Venvironments\\Lib\\site-packages\\httpcore\\_backends\\sync.py:126\u001B[0m, in \u001B[0;36mSyncStream.read\u001B[1;34m(self, max_bytes, timeout)\u001B[0m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m map_exceptions(exc_map):\n\u001B[0;32m    125\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sock\u001B[38;5;241m.\u001B[39msettimeout(timeout)\n\u001B[1;32m--> 126\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmax_bytes\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1263\u001B[0m, in \u001B[0;36mSSLSocket.recv\u001B[1;34m(self, buflen, flags)\u001B[0m\n\u001B[0;32m   1259\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1260\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1261\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[0;32m   1262\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[1;32m-> 1263\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbuflen\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1264\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1265\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv(buflen, flags)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1136\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[1;34m(self, len, buffer)\u001B[0m\n\u001B[0;32m   1134\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m, buffer)\n\u001B[0;32m   1135\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1136\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1137\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m SSLError \u001B[38;5;28;01mas\u001B[39;00m x:\n\u001B[0;32m   1138\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39margs[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m==\u001B[39m SSL_ERROR_EOF \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msuppress_ragged_eofs:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Matrix Evaluation",
   "id": "2606f1d83001ce3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:27:10.707218Z",
     "start_time": "2024-12-16T03:27:08.439301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build matrix\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from helper.cluster_analysis import *\n",
    "\n",
    "sample_for_embedding = os.path.join(root_dir, steam_title, \"sample_for_embedding.json\")\n",
    "input = os.path.join(root_dir, steam_title, f\"{methode}_embedding.json\")\n",
    "\n",
    "param_grid = {\n",
    "    'min_cluster_size': [3, 5, 7, 10, 15],\n",
    "    'min_samples': [1, 2, 3, 4, 5, 7, 10],\n",
    "    'cluster_selection_epsilon': [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "}\n",
    "grid = ParameterGrid(param_grid)\n",
    "\n",
    "sample_df = read_json(input)\n",
    "sampled_mat = np.array([entry['embedding'] for entry in sample_df])\n",
    "# Reduce dimensions\n",
    "\n",
    "# Step 3: Reduce Dimensionality with UMAP\n",
    "# Reduce the original 3075 dimensions to 20 dimensions\n",
    "reducer = umap.UMAP(n_components=20, random_state=42)\n",
    "mat_reduced = reducer.fit_transform(sampled_mat)\n",
    "\n",
    "# Step 5: Apply HDBSCAN to Each Parameter Combination and Evaluate Results\n",
    "results = []\n",
    "\n",
    "for params in grid:\n",
    "    clusterer = hdbscan.HDBSCAN(\n",
    "        min_cluster_size=params['min_cluster_size'],\n",
    "        min_samples=params['min_samples'],\n",
    "        cluster_selection_epsilon=params['cluster_selection_epsilon']\n",
    "    )\n",
    "    labels = clusterer.fit_predict(mat_reduced)\n",
    "    #print(labels)\n",
    "\n",
    "    # Number of clusters (excluding noise, which is labeled as -1)\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    # Proportion of noise points\n",
    "    noise_ratio = sum(labels == -1) / len(labels)\n",
    "\n",
    "    # Store the results for analysis\n",
    "    results.append({\n",
    "        'params': params,\n",
    "        'n_clusters': n_clusters,\n",
    "        'noise_ratio': noise_ratio\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame for easier analysis\n",
    "results_df = pd.DataFrame(results)\n",
    "optimal_results = results_df.sort_values(by=['noise_ratio', 'n_clusters'], ascending=[True, False])\n",
    "best_params = optimal_results.iloc[0]"
   ],
   "id": "fc0559be6233ed4b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fbohm\\Documents\\Venvironments\\Lib\\site-packages\\umap\\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:27:13.342721Z",
     "start_time": "2024-12-16T03:27:13.332509Z"
    }
   },
   "cell_type": "code",
   "source": "results_df",
   "id": "d4c78ad7a874570b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                                            params  \\\n",
       "0      {'cluster_selection_epsilon': 0.1, 'min_cluster_size': 3, 'min_samples': 1}   \n",
       "1      {'cluster_selection_epsilon': 0.1, 'min_cluster_size': 3, 'min_samples': 2}   \n",
       "2      {'cluster_selection_epsilon': 0.1, 'min_cluster_size': 3, 'min_samples': 3}   \n",
       "3      {'cluster_selection_epsilon': 0.1, 'min_cluster_size': 3, 'min_samples': 4}   \n",
       "4      {'cluster_selection_epsilon': 0.1, 'min_cluster_size': 3, 'min_samples': 5}   \n",
       "..                                                                             ...   \n",
       "170   {'cluster_selection_epsilon': 0.9, 'min_cluster_size': 15, 'min_samples': 3}   \n",
       "171   {'cluster_selection_epsilon': 0.9, 'min_cluster_size': 15, 'min_samples': 4}   \n",
       "172   {'cluster_selection_epsilon': 0.9, 'min_cluster_size': 15, 'min_samples': 5}   \n",
       "173   {'cluster_selection_epsilon': 0.9, 'min_cluster_size': 15, 'min_samples': 7}   \n",
       "174  {'cluster_selection_epsilon': 0.9, 'min_cluster_size': 15, 'min_samples': 10}   \n",
       "\n",
       "     n_clusters  noise_ratio  \n",
       "0            34     0.092369  \n",
       "1             2     0.000000  \n",
       "2             2     0.000000  \n",
       "3             2     0.000000  \n",
       "4             2     0.000000  \n",
       "..          ...          ...  \n",
       "170           2     0.200803  \n",
       "171           2     0.096386  \n",
       "172           2     0.136546  \n",
       "173           2     0.204819  \n",
       "174           2     0.325301  \n",
       "\n",
       "[175 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>n_clusters</th>\n",
       "      <th>noise_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'cluster_selection_epsilon': 0.1, 'min_cluster_size': 3, 'min_samples': 1}</td>\n",
       "      <td>34</td>\n",
       "      <td>0.092369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'cluster_selection_epsilon': 0.1, 'min_cluster_size': 3, 'min_samples': 2}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'cluster_selection_epsilon': 0.1, 'min_cluster_size': 3, 'min_samples': 3}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'cluster_selection_epsilon': 0.1, 'min_cluster_size': 3, 'min_samples': 4}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'cluster_selection_epsilon': 0.1, 'min_cluster_size': 3, 'min_samples': 5}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>{'cluster_selection_epsilon': 0.9, 'min_cluster_size': 15, 'min_samples': 3}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.200803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>{'cluster_selection_epsilon': 0.9, 'min_cluster_size': 15, 'min_samples': 4}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.096386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>{'cluster_selection_epsilon': 0.9, 'min_cluster_size': 15, 'min_samples': 5}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.136546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>{'cluster_selection_epsilon': 0.9, 'min_cluster_size': 15, 'min_samples': 7}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.204819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>{'cluster_selection_epsilon': 0.9, 'min_cluster_size': 15, 'min_samples': 10}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.325301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "bd3d3890a796ba77"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:27:27.299686Z",
     "start_time": "2024-12-16T03:27:24.085857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Adjustable parameters\n",
    "dimensionality_methods = ['UMAP','PCA', 'tSNE']\n",
    "hdbscan_params = {\"min_cluster_size\": 10, \"min_samples\": 1, \"cluster_selection_epsilon\": 0.5}\n",
    "\n",
    "# Step 3: Reduce Dimensionality with UMAP\n",
    "# Reduce the original 3075 dimensions to 20 dimensions\n",
    "reducer = umap.UMAP(n_components=20, random_state=42)\n",
    "mat_reduced = reducer.fit_transform(sampled_mat)\n",
    "\n",
    "open_ai_embedding = os.path.join(root_dir, steam_title, f\"{methode}_embedding.json\")\n",
    "sample_df = load_embedded_data(open_ai_embedding)\n",
    "# Apply HDBSCAN\n",
    "df_total = apply_hdbscan(\n",
    "    sample_df,\n",
    "    mat_reduced,\n",
    "    dimensionality_methods,\n",
    "    hdbscan_params=hdbscan_params,\n",
    "    include_2d=True,\n",
    "    include_3d=True\n",
    ")\n",
    "\n",
    "# Save results\n",
    "output_file = os.path.join(root_dir, steam_title, f\"{methode}_2_cluster.json\")\n",
    "save_df_as_json(df_total, output_file)\n",
    "logger.info(f\"Results saved to {output_file}\")"
   ],
   "id": "a29c5a1364104d70",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fbohm\\Documents\\Venvironments\\Lib\\site-packages\\umap\\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "2024-12-16 16:27:24,693 - INFO - Loading data from C:\\Users\\fbohm\\Desktop\\Projects\\DataScience\\cluster_analysis\\Data\\Steamapps\\Market\\mpnet_embedding.json\n",
      "2024-12-16 16:27:24,881 - INFO - Loaded 249 valid entries with embeddings.\n",
      "2024-12-16 16:27:24,884 - INFO - Applying HDBSCAN with: {'min_cluster_size': 10, 'min_samples': 1, 'cluster_selection_epsilon': 0.5}\n",
      "2024-12-16 16:27:24,898 - INFO - Found 5 clusters.\n",
      "2024-12-16 16:27:24,899 - INFO - Applying UMAP with 2 components.\n",
      "2024-12-16 16:27:25,059 - INFO - Applying UMAP with 3 components.\n",
      "2024-12-16 16:27:25,281 - INFO - Applying PCA with 2 components.\n",
      "2024-12-16 16:27:25,296 - INFO - Applying PCA with 3 components.\n",
      "2024-12-16 16:27:25,298 - INFO - Applying tSNE with 2 components.\n",
      "2024-12-16 16:27:25,299 - INFO - Perplexity not provided, setting to 30 based on sample size.\n",
      "2024-12-16 16:27:26,009 - INFO - Applying tSNE with 3 components.\n",
      "2024-12-16 16:27:26,010 - INFO - Perplexity not provided, setting to 30 based on sample size.\n",
      "2024-12-16 16:27:26,830 - INFO - HDBSCAN clustering and dimensionality reduction completed.\n",
      "2024-12-16 16:27:26,836 - INFO - Saving data to C:\\Users\\fbohm\\Desktop\\Projects\\DataScience\\cluster_analysis\\Data\\Steamapps\\Market\\mpnet_2_cluster.json\n",
      "2024-12-16 16:27:27,297 - INFO - Results saved to C:\\Users\\fbohm\\Desktop\\Projects\\DataScience\\cluster_analysis\\Data\\Steamapps\\Market\\mpnet_2_cluster.json\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T03:27:31.799313Z",
     "start_time": "2024-12-16T03:27:29.256637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from helper.cluster_naming import *\n",
    "# Parameters\n",
    "dimensionality_methods = [\"UMAP\",'PCA', \"tSNE\"]\n",
    "clustering_algorithms = [\"hdbscan\"]  # No KMeans here\n",
    "max_centers = 10\n",
    "\n",
    "#kmeans_clusters = [15, 20, 25, 50]  # Number of clusters for KMeans\n",
    "\n",
    "openai_clustered = os.path.join(root_dir, steam_title, f\"{methode}_2_cluster.json\")\n",
    "# Load data\n",
    "df_total = load_json_into_df(openai_clustered)\n",
    "\n",
    "# Process clusters and generate names\n",
    "df_total = process_clusters(\n",
    "    df_total, \n",
    "    dimensionality_methods, \n",
    "    clustering_algorithms, \n",
    "    max_centers, \n",
    "    api_settings) # insert kmeans_clusters in the function when needed\n",
    "\n",
    "\n",
    "# Save results\n",
    "output_file = os.path.join(root_dir, steam_title, f\"{methode}_3_named.json\")\n",
    "save_data_for_streamlit(df_total, output_file)"
   ],
   "id": "d8524d0fa60727e1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 16:27:29,259 - INFO - Loading data from C:\\Users\\fbohm\\Desktop\\Projects\\DataScience\\cluster_analysis\\Data\\Steamapps\\Market\\mpnet_2_cluster.json\n",
      "2024-12-16 16:27:29,385 - INFO - Found 10 Topics for hdbscan_cluster_id ID: 3\n",
      "2024-12-16 16:27:29,939 - INFO - Generated cluster name: Early Access Gameplay Challenges\n",
      "2024-12-16 16:27:29,940 - INFO - Tokens used so far: Prompt Tokens: 7922, Completion Tokens: 223\n",
      "2024-12-16 16:27:29,953 - INFO - Found 10 Topics for hdbscan_cluster_id ID: 1\n",
      "2024-12-16 16:27:30,505 - INFO - Generated cluster name: Gameplay and Mechanics Overview\n",
      "2024-12-16 16:27:30,506 - INFO - Tokens used so far: Prompt Tokens: 8030, Completion Tokens: 227\n",
      "2024-12-16 16:27:30,511 - INFO - Found 10 Topics for hdbscan_cluster_id ID: 0\n",
      "2024-12-16 16:27:31,111 - INFO - Generated cluster name: Game Enthusiasm and Future Outlook\n",
      "2024-12-16 16:27:31,112 - INFO - Tokens used so far: Prompt Tokens: 8230, Completion Tokens: 233\n",
      "2024-12-16 16:27:31,116 - INFO - Found 10 Topics for hdbscan_cluster_id ID: 2\n",
      "2024-12-16 16:27:31,674 - INFO - Generated cluster name: Game Enjoyment and Crafting Experience\n",
      "2024-12-16 16:27:31,674 - INFO - Tokens used so far: Prompt Tokens: 8493, Completion Tokens: 240\n",
      "2024-12-16 16:27:31,683 - INFO - Found 10 Topics for hdbscan_cluster_id ID: 3\n",
      "2024-12-16 16:27:31,691 - INFO - Found 10 Topics for hdbscan_cluster_id ID: 1\n",
      "2024-12-16 16:27:31,695 - INFO - Found 10 Topics for hdbscan_cluster_id ID: 0\n",
      "2024-12-16 16:27:31,700 - INFO - Found 10 Topics for hdbscan_cluster_id ID: 2\n",
      "2024-12-16 16:27:31,708 - INFO - Found 10 Topics for hdbscan_cluster_id ID: 3\n",
      "2024-12-16 16:27:31,722 - INFO - Found 10 Topics for hdbscan_cluster_id ID: 1\n",
      "2024-12-16 16:27:31,727 - INFO - Found 10 Topics for hdbscan_cluster_id ID: 0\n",
      "2024-12-16 16:27:31,732 - INFO - Found 10 Topics for hdbscan_cluster_id ID: 2\n",
      "2024-12-16 16:27:31,736 - INFO - Cluster naming process completed.\n",
      "2024-12-16 16:27:31,736 - INFO - Saving updated data to C:\\Users\\fbohm\\Desktop\\Projects\\DataScience\\cluster_analysis\\Data\\Steamapps\\Market\\mpnet_3_named.json\n",
      "2024-12-16 16:27:31,795 - INFO - Data saved successfully.\n"
     ]
    }
   ],
   "execution_count": 67
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
