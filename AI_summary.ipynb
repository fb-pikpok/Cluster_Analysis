{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-17T20:52:49.176807Z",
     "start_time": "2025-03-17T20:52:49.137264Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "input_path = r'S:\\SID\\Analytics\\Working Files\\Individual\\Florian\\Projects\\DataScience\\cluster_analysis\\Data\\Backup\\DRS_NextFest\\db_final.json'\n",
    "with open(input_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         pp_id                                           document  \\\n",
       "0  next_fest_1                          Stealth kills from cover.   \n",
       "1  next_fest_2                                      Random events   \n",
       "2  next_fest_3                              base defense upgrades   \n",
       "3  next_fest_4                   weapon upgrades on basic weapons   \n",
       "4  next_fest_5  The option to make your own notes or marks on ...   \n",
       "\n",
       "   Collector ID Custom Data 1 Email Address First Name  \\\n",
       "0     459707592                                          \n",
       "1     459707592                                          \n",
       "2     459707592                                          \n",
       "3     459707592                                          \n",
       "4     459707592                                          \n",
       "\n",
       "  Had you heard of Into the Dead before this demo? IP Address Last Name  \\\n",
       "0                                Never heard of it                        \n",
       "1                                Never heard of it                        \n",
       "2                                Never heard of it                        \n",
       "3                                Never heard of it                        \n",
       "4                                      Heard of it                        \n",
       "\n",
       "  Please rank what matters most to you about Into the Dead: Our Darkest Days:  \\\n",
       "0                                                5.0                            \n",
       "1                                                3.0                            \n",
       "2                                                3.0                            \n",
       "3                                                3.0                            \n",
       "4                                                3.0                            \n",
       "\n",
       "   ...  session_count session_length  spending  test_group  \\\n",
       "0  ...           10.0         5880.0                         \n",
       "1  ...            4.0         4814.0                         \n",
       "2  ...            4.0         4814.0                         \n",
       "3  ...            4.0         4814.0                         \n",
       "4  ...            7.0         5572.0                         \n",
       "\n",
       "                   topic    version hdbscan_id hdbscan_UMAP_2D_x  \\\n",
       "0      Stealth Mechanics  v0.1.7901         13         19.438429   \n",
       "1          Random Events                     2          7.944154   \n",
       "2  Base Defense Upgrades                    -1          4.001101   \n",
       "3        Weapon Upgrades                     1          6.407705   \n",
       "4       Map Note Feature                     4          0.132544   \n",
       "\n",
       "  hdbscan_UMAP_2D_y                    hdbscan_id_name  \n",
       "0          5.584411      Stealth Zombie Kill Mechanics  \n",
       "1          0.386788  Dynamic Randomization in Gameplay  \n",
       "2          6.561998                              Noise  \n",
       "3         -9.599965  Weapon Customization and Upgrades  \n",
       "4          5.202775         Loot Tracking Enhancements  \n",
       "\n",
       "[5 rows x 87 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pp_id</th>\n",
       "      <th>document</th>\n",
       "      <th>Collector ID</th>\n",
       "      <th>Custom Data 1</th>\n",
       "      <th>Email Address</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Had you heard of Into the Dead before this demo?</th>\n",
       "      <th>IP Address</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Please rank what matters most to you about Into the Dead: Our Darkest Days:</th>\n",
       "      <th>...</th>\n",
       "      <th>session_count</th>\n",
       "      <th>session_length</th>\n",
       "      <th>spending</th>\n",
       "      <th>test_group</th>\n",
       "      <th>topic</th>\n",
       "      <th>version</th>\n",
       "      <th>hdbscan_id</th>\n",
       "      <th>hdbscan_UMAP_2D_x</th>\n",
       "      <th>hdbscan_UMAP_2D_y</th>\n",
       "      <th>hdbscan_id_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>next_fest_1</td>\n",
       "      <td>Stealth kills from cover.</td>\n",
       "      <td>459707592</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Never heard of it</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5880.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Stealth Mechanics</td>\n",
       "      <td>v0.1.7901</td>\n",
       "      <td>13</td>\n",
       "      <td>19.438429</td>\n",
       "      <td>5.584411</td>\n",
       "      <td>Stealth Zombie Kill Mechanics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>next_fest_2</td>\n",
       "      <td>Random events</td>\n",
       "      <td>459707592</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Never heard of it</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4814.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Random Events</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>7.944154</td>\n",
       "      <td>0.386788</td>\n",
       "      <td>Dynamic Randomization in Gameplay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>next_fest_3</td>\n",
       "      <td>base defense upgrades</td>\n",
       "      <td>459707592</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Never heard of it</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4814.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Base Defense Upgrades</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>4.001101</td>\n",
       "      <td>6.561998</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>next_fest_4</td>\n",
       "      <td>weapon upgrades on basic weapons</td>\n",
       "      <td>459707592</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Never heard of it</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4814.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Weapon Upgrades</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>6.407705</td>\n",
       "      <td>-9.599965</td>\n",
       "      <td>Weapon Customization and Upgrades</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>next_fest_5</td>\n",
       "      <td>The option to make your own notes or marks on ...</td>\n",
       "      <td>459707592</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Heard of it</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5572.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Map Note Feature</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.132544</td>\n",
       "      <td>5.202775</td>\n",
       "      <td>Loot Tracking Enhancements</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 87 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T20:52:49.191926Z",
     "start_time": "2025-03-17T20:52:49.176807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_hard_facts(df):\n",
    "    \"\"\"\n",
    "    Summarize a DataFrame containing columns:\n",
    "      - 'sentence' : the user/player statement (str)\n",
    "      - 'sentiment': the sentiment label (e.g. 'positive', 'negative', 'inconclusive')\n",
    "      - 'hdbscan_id_name': name of the cluster\n",
    "      - 'topic' : a short \"headline\" or summary for each statement\n",
    "\n",
    "    Returns a DataFrame with:\n",
    "      - total_data_points\n",
    "      - sentiment counts (positive, negative, inconclusive)\n",
    "      - a list of all unique topics for that cluster\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Count the total data points (statements) per cluster\n",
    "    cluster_counts = (\n",
    "        df.groupby('hdbscan_id_name', dropna=False)['sentence']\n",
    "          .count()\n",
    "          .reset_index(name='total_data_points')\n",
    "    )\n",
    "\n",
    "    # 2. Count how many are positive, negative, etc. in each cluster\n",
    "    sentiment_counts = (\n",
    "        df.groupby(['hdbscan_id_name', 'sentiment'])['sentence']\n",
    "          .count()\n",
    "          .reset_index(name='count')\n",
    "    )\n",
    "\n",
    "    # 3. Pivot the sentiment counts so each cluster is one row, with separate sentiment columns\n",
    "    sentiment_pivot = (\n",
    "        sentiment_counts\n",
    "        .pivot_table(index='hdbscan_id_name',\n",
    "                     columns='sentiment',\n",
    "                     values='count',\n",
    "                     fill_value=0)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # 4. Merge the pivot back with the total cluster counts\n",
    "    cluster_summary_df = cluster_counts.merge(\n",
    "        sentiment_pivot,\n",
    "        on='hdbscan_id_name',\n",
    "        how='left'\n",
    "    )\n",
    "    # 4.5. Exclude \"Noise\" cluster\n",
    "    cluster_summary_df = cluster_summary_df[cluster_summary_df['hdbscan_id_name'] != \"Noise\"]\n",
    "\n",
    "    # 5. Rename the sentiment columns for clarity (if they exist)\n",
    "    rename_map = {}\n",
    "    for col in ['positive', 'negative', 'inconclusive']:\n",
    "        if col in cluster_summary_df.columns:\n",
    "            rename_map[col] = f\"{col}_count\"\n",
    "    cluster_summary_df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "    # 6. Get all unique topic values per cluster\n",
    "    topics_per_cluster = (\n",
    "        df.groupby('hdbscan_id_name')['topic']\n",
    "          .unique()\n",
    "          .reset_index(name='unique_topics')\n",
    "    )\n",
    "\n",
    "    # 7. Merge unique topics into the cluster summary\n",
    "    cluster_summary_df = cluster_summary_df.merge(\n",
    "        topics_per_cluster,\n",
    "        on='hdbscan_id_name',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Sort by cluster name if you like (optional)\n",
    "    cluster_summary_df.sort_values(by='hdbscan_id_name', inplace=True)\n",
    "\n",
    "    return cluster_summary_df\n"
   ],
   "id": "c9152a61d25f1413",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T20:52:49.262900Z",
     "start_time": "2025-03-17T20:52:49.248449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Generate the cluster summary\n",
    "summary_df = generate_hard_facts(df)\n",
    "\n",
    "# Print or do further processing\n",
    "print(summary_df.head())"
   ],
   "id": "8850a20d36e57ff9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             hdbscan_id_name  total_data_points  Inconclusive  \\\n",
      "0  \"Enhanced Movement and Animation Quality\"                 21           9.0   \n",
      "1              Auto Weapon Management System                 19          14.0   \n",
      "2           Backpack and Inventory Expansion                 26          21.0   \n",
      "3            Character Customization Options                 21          14.0   \n",
      "4   Character Interactions and Relationships                 42          27.0   \n",
      "\n",
      "   Negative  Positive                                      unique_topics  \n",
      "0       7.0       5.0  [Performance Issues, Experience Variety, Game ...  \n",
      "1       4.0       1.0  [Weapon Slot, Quick Switch Functionality, Auto...  \n",
      "2       4.0       1.0  [Inventory Management, Backpack Crafting, Back...  \n",
      "3       4.0       3.0  [Character Customization, Character Variety, T...  \n",
      "4       8.0       7.0  [Language Option, Character Interaction, Chara...  \n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# AI Summary",
   "id": "8982392e570fd0ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T01:20:19.341223Z",
     "start_time": "2025-03-18T01:20:19.149992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import openai\n",
    "import os\n",
    "import logging\n",
    "from dotenv import dotenv_values\n",
    "import json\n",
    "\n",
    "from helper.utils import configure_api\n",
    "d = dotenv_values()\n",
    "for k in d.keys():\n",
    "    os.environ[k] = d[k]\n",
    "\n",
    "# General modules\n",
    "\n",
    "# Setup API keys\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_key = openai_api_key\n",
    "client = openai.Client()\n",
    "\n",
    "# Specify models\n",
    "chat_model_name = 'gpt-4o-mini'\n",
    "openai_embedding_model = \"text-embedding-3-small\"\n",
    "local_embedding_model = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "configure_api(client, chat_model_name)\n",
    "\n",
    "# Specify paths for storing (backup) data\n",
    "root_dir = r'S:\\SID\\Analytics\\Working Files\\Individual\\Florian\\Projects\\DataScience\\cluster_analysis\\Data\\Backup'\n",
    "project = 'HRC_Survey_T3_2024'\n",
    "\n",
    "# Setup the logger\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.getLogger(\"httpx\").setLevel(logging.ERROR)      # Supress API HTTP request logs"
   ],
   "id": "afafad448ca2326a",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T01:20:59.699237Z",
     "start_time": "2025-03-18T01:20:59.689410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from helper.prompt_templates import *\n",
    "from helper.utils import api_settings\n",
    "\n",
    "\n",
    "# Initialize global token counters\n",
    "prompt_tokens = 0\n",
    "completion_tokens = 0\n",
    "\n",
    "def track_tokens(response):\n",
    "    \"\"\"\n",
    "    Updates the global token counters based on the API response.\n",
    "\n",
    "    Args:\n",
    "        response: The API response containing token usage.\n",
    "    \"\"\"\n",
    "    global prompt_tokens, completion_tokens\n",
    "    prompt_tokens += response.usage.prompt_tokens\n",
    "    completion_tokens += response.usage.completion_tokens\n",
    "\n",
    "\n",
    "def generate_cluster_report(\n",
    "    df: pd.DataFrame\n",
    "):\n",
    "        # 1. Count the total data points (statements) per cluster\n",
    "    cluster_counts = (\n",
    "        df.groupby('hdbscan_id_name', dropna=False)['sentence']\n",
    "          .count()\n",
    "          .reset_index(name='number_of_statements')\n",
    "    )\n",
    "\n",
    "    # 2. Count how many are positive, negative, etc. in each cluster\n",
    "    sentiment_counts = (\n",
    "        df.groupby(['hdbscan_id_name', 'sentiment'])['sentence']\n",
    "          .count()\n",
    "          .reset_index(name='count')\n",
    "    )\n",
    "\n",
    "    # 3. Pivot the sentiment counts so each cluster is one row, with separate sentiment columns\n",
    "    sentiment_pivot = (\n",
    "        sentiment_counts\n",
    "        .pivot_table(index='hdbscan_id_name',\n",
    "                     columns='sentiment',\n",
    "                     values='count',\n",
    "                     fill_value=0)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # 4. Merge the pivot back with the total cluster counts\n",
    "    cluster_summary_df = cluster_counts.merge(\n",
    "        sentiment_pivot,\n",
    "        on='hdbscan_id_name',\n",
    "        how='left'\n",
    "    )\n",
    "    # 4.5. Exclude \"Noise\" cluster\n",
    "    cluster_summary_df = cluster_summary_df[cluster_summary_df['hdbscan_id_name'] != \"Noise\"]\n",
    "\n",
    "    # 5. Rename the sentiment columns for clarity (if they exist)\n",
    "    rename_map = {}\n",
    "    for col in ['positive', 'negative', 'inconclusive']:\n",
    "        if col in cluster_summary_df.columns:\n",
    "            rename_map[col] = f\"{col}_count\"\n",
    "    cluster_summary_df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "\n",
    "    # Sort by total_data_points DESCENDING so the largest cluster is first\n",
    "    cluster_summary_df.sort_values(by='number_of_statements', ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "    # We'll accumulate everything into one big string of Markdown\n",
    "    markdown_report = \"# Cluster Report\\n\\n\"\n",
    "\n",
    "    # Create a dict mapping cluster -> list of statements\n",
    "    cluster_to_statements = (\n",
    "        df.groupby('hdbscan_id_name')['sentence']\n",
    "          .apply(list)\n",
    "          .to_dict()\n",
    "    )\n",
    "\n",
    "    for _, row in cluster_summary_df.iterrows():\n",
    "        cluster_name = row['hdbscan_id_name']\n",
    "\n",
    "        total_points = row['number_of_statements']\n",
    "        positive_count = int(row.get('Positive', 0))\n",
    "        negative_count = int(row.get('Negative', 0))\n",
    "        inconclusive_count = int(row.get('Inconclusive', 0))\n",
    "\n",
    "        # ---------------------------------------------------\n",
    "        # 2a) Write \"hard facts\" as a small Markdown table\n",
    "        # ---------------------------------------------------\n",
    "        markdown_report += f\"## Cluster: {cluster_name}\\n\\n\"\n",
    "        markdown_report += \"### Hard Facts\\n\\n\"\n",
    "        markdown_report += \"| Metric              | Value |\\n\"\n",
    "        markdown_report += \"|---------------------|-------|\\n\"\n",
    "        markdown_report += f\"| **Total Statements**       | {total_points} |\\n\"\n",
    "        markdown_report += f\"| **Positive Count**          | {positive_count} |\\n\"\n",
    "        markdown_report += f\"| **Negative Count**          | {negative_count} |\\n\"\n",
    "        markdown_report += f\"| **Inconclusive Count**      | {inconclusive_count} |\\n\\n\"\n",
    "\n",
    "        # ---------------------------------------------------\n",
    "        # 2b) Get statements and call the OpenAI API for summary\n",
    "        # ---------------------------------------------------\n",
    "        statements_for_this_cluster = cluster_to_statements[cluster_name]\n",
    "        # If many statements, consider chunking or sampling\n",
    "        statements_text = \"\\n\".join(f\"- {s}\" for s in statements_for_this_cluster)\n",
    "\n",
    "#######################\n",
    "        prompt_topic = prompt_template_summary_short.format(cluster_name=cluster_name, statements =statements_text, video_game = \"Rival Stars Horse Racing\")\n",
    "        logger.info(f\"Generate AI summary for cluster {cluster_name}\")\n",
    "\n",
    "        try:\n",
    "            response = api_settings[\"client\"].chat.completions.create(\n",
    "                model=api_settings[\"model\"],\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an expert summarizing user statements for a video game.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt_topic},\n",
    "                ]\n",
    "            )\n",
    "            track_tokens(response)\n",
    "            summary_text = response.choices[0].message.content.strip()\n",
    "            logger.info(f\"Total tokens used: {prompt_tokens + completion_tokens}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error summarizing cluster {cluster_name}: {e}\")\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "\n",
    "\n",
    "        # ---------------------------------------------------\n",
    "        # 2c) Append the summary to the Markdown\n",
    "        # ---------------------------------------------------\n",
    "        markdown_report += \"### Key Insights\\n\\n\"\n",
    "        markdown_report += summary_text + \"\\n\\n\"\n",
    "        markdown_report += \"---\\n\\n\"\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # STEP 3: Write the final Markdown to file\n",
    "    # ---------------------------------------------------\n",
    "    logger.info(\"Markdown Report has been written.\")\n",
    "\n",
    "    return markdown_report\n"
   ],
   "id": "18693b0d5e91fb2e",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T01:21:06.488477Z",
     "start_time": "2025-03-18T01:21:05.892851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_path = os.path.join(root_dir, project, \"db_final.json\")\n",
    "with open(input_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ],
   "id": "1850c258acf0b5f1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  pp_id                                           document  \\\n",
       "0  HRC_survey_t3_2024_1  Takes too long without star club, it's just wa...   \n",
       "1  HRC_survey_t3_2024_2  In-app photo contests, voting like in Design g...   \n",
       "2  HRC_survey_t3_2024_3  Ways to earn prizes for breeding horses for ae...   \n",
       "3  HRC_survey_t3_2024_4                                More cross country.   \n",
       "4  HRC_survey_t3_2024_5  Sell a horse (because stable is maxed): view a...   \n",
       "\n",
       "  10_On a scale from 1-5, how has the Crossbreeding and Traits affected your OVERALL experience?  \\\n",
       "0                      (5) Made the game much better                                               \n",
       "1                      (5) Made the game much better                                               \n",
       "2                      (5) Made the game much better                                               \n",
       "3                      (5) Made the game much better                                               \n",
       "4                      (5) Made the game much better                                               \n",
       "\n",
       "  10_Optional] Please explain why you rated your experience with Crossbreeding & Traits this way.  \\\n",
       "0              I like any customization and strategy                                                \n",
       "1              I like any customization and strategy                                                \n",
       "2              I like any customization and strategy                                                \n",
       "3              I like any customization and strategy                                                \n",
       "4              I like any customization and strategy                                                \n",
       "\n",
       "  11_In the past 3 months, about how much money have you spent on mobile games?  \\\n",
       "0                                           $50+ USD                              \n",
       "1                                           $50+ USD                              \n",
       "2                                           $50+ USD                              \n",
       "3                                           $50+ USD                              \n",
       "4                                           $50+ USD                              \n",
       "\n",
       "  12_In App Purchases (paying for exclusive content)  \\\n",
       "0    In App Purchases (paying for exclusive content)   \n",
       "1    In App Purchases (paying for exclusive content)   \n",
       "2    In App Purchases (paying for exclusive content)   \n",
       "3    In App Purchases (paying for exclusive content)   \n",
       "4    In App Purchases (paying for exclusive content)   \n",
       "\n",
       "  12_None of the above_In the past 3 months, have you spent real money to purchase the following in mobile games? (Select all that apply)  \\\n",
       "0                                                                                                                                           \n",
       "1                                                                                                                                           \n",
       "2                                                                                                                                           \n",
       "3                                                                                                                                           \n",
       "4                                                                                                                                           \n",
       "\n",
       "  12_Premium (pay upfront for the entire game)  \\\n",
       "0                                                \n",
       "1                                                \n",
       "2                                                \n",
       "3                                                \n",
       "4                                                \n",
       "\n",
       "  12_Remove ads (pay once to remove in-game ads)  \\\n",
       "0                                                  \n",
       "1                                                  \n",
       "2                                                  \n",
       "3                                                  \n",
       "4                                                  \n",
       "\n",
       "  12_Subscriptions (paying weekly, monthly, or annually for content)  ...  \\\n",
       "0                                                                     ...   \n",
       "1                                                                     ...   \n",
       "2                                                                     ...   \n",
       "3                                                                     ...   \n",
       "4                                                                     ...   \n",
       "\n",
       "     spending standard_team_races test_group                         topic  \\\n",
       "0  245.355994               505.0                       Star Club Duration   \n",
       "1  245.355994               505.0                Photo Contests and Voting   \n",
       "2  245.355994               505.0               Breeding Aesthetic Rewards   \n",
       "3  245.355994               505.0                     Cross Country Events   \n",
       "4  245.355994               505.0             Horse Selling and Stats View   \n",
       "\n",
       "  hdbscan_id hdbscan_UMAP_2D_x hdbscan_UMAP_2D_y hdbscan_tSNE_2D_x  \\\n",
       "0         11          6.391001         16.935848        -21.588978   \n",
       "1         -1         10.835783         -1.045431         -8.794202   \n",
       "2         -1          8.322358          0.338659          7.157442   \n",
       "3         19         15.967313          4.156400          7.117190   \n",
       "4         -1          1.321768          3.327364         26.394068   \n",
       "\n",
       "  hdbscan_tSNE_2D_y                           hdbscan_id_name  \n",
       "0         63.965237              Equal Access for All Players  \n",
       "1         25.302008                                     Noise  \n",
       "2         -8.243853                                     Noise  \n",
       "3        -39.889538  Race Preferences: Flat vs. Cross-Country  \n",
       "4         21.343136                                     Noise  \n",
       "\n",
       "[5 rows x 168 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pp_id</th>\n",
       "      <th>document</th>\n",
       "      <th>10_On a scale from 1-5, how has the Crossbreeding and Traits affected your OVERALL experience?</th>\n",
       "      <th>10_Optional] Please explain why you rated your experience with Crossbreeding &amp; Traits this way.</th>\n",
       "      <th>11_In the past 3 months, about how much money have you spent on mobile games?</th>\n",
       "      <th>12_In App Purchases (paying for exclusive content)</th>\n",
       "      <th>12_None of the above_In the past 3 months, have you spent real money to purchase the following in mobile games? (Select all that apply)</th>\n",
       "      <th>12_Premium (pay upfront for the entire game)</th>\n",
       "      <th>12_Remove ads (pay once to remove in-game ads)</th>\n",
       "      <th>12_Subscriptions (paying weekly, monthly, or annually for content)</th>\n",
       "      <th>...</th>\n",
       "      <th>spending</th>\n",
       "      <th>standard_team_races</th>\n",
       "      <th>test_group</th>\n",
       "      <th>topic</th>\n",
       "      <th>hdbscan_id</th>\n",
       "      <th>hdbscan_UMAP_2D_x</th>\n",
       "      <th>hdbscan_UMAP_2D_y</th>\n",
       "      <th>hdbscan_tSNE_2D_x</th>\n",
       "      <th>hdbscan_tSNE_2D_y</th>\n",
       "      <th>hdbscan_id_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HRC_survey_t3_2024_1</td>\n",
       "      <td>Takes too long without star club, it's just wa...</td>\n",
       "      <td>(5) Made the game much better</td>\n",
       "      <td>I like any customization and strategy</td>\n",
       "      <td>$50+ USD</td>\n",
       "      <td>In App Purchases (paying for exclusive content)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>245.355994</td>\n",
       "      <td>505.0</td>\n",
       "      <td></td>\n",
       "      <td>Star Club Duration</td>\n",
       "      <td>11</td>\n",
       "      <td>6.391001</td>\n",
       "      <td>16.935848</td>\n",
       "      <td>-21.588978</td>\n",
       "      <td>63.965237</td>\n",
       "      <td>Equal Access for All Players</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HRC_survey_t3_2024_2</td>\n",
       "      <td>In-app photo contests, voting like in Design g...</td>\n",
       "      <td>(5) Made the game much better</td>\n",
       "      <td>I like any customization and strategy</td>\n",
       "      <td>$50+ USD</td>\n",
       "      <td>In App Purchases (paying for exclusive content)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>245.355994</td>\n",
       "      <td>505.0</td>\n",
       "      <td></td>\n",
       "      <td>Photo Contests and Voting</td>\n",
       "      <td>-1</td>\n",
       "      <td>10.835783</td>\n",
       "      <td>-1.045431</td>\n",
       "      <td>-8.794202</td>\n",
       "      <td>25.302008</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HRC_survey_t3_2024_3</td>\n",
       "      <td>Ways to earn prizes for breeding horses for ae...</td>\n",
       "      <td>(5) Made the game much better</td>\n",
       "      <td>I like any customization and strategy</td>\n",
       "      <td>$50+ USD</td>\n",
       "      <td>In App Purchases (paying for exclusive content)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>245.355994</td>\n",
       "      <td>505.0</td>\n",
       "      <td></td>\n",
       "      <td>Breeding Aesthetic Rewards</td>\n",
       "      <td>-1</td>\n",
       "      <td>8.322358</td>\n",
       "      <td>0.338659</td>\n",
       "      <td>7.157442</td>\n",
       "      <td>-8.243853</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HRC_survey_t3_2024_4</td>\n",
       "      <td>More cross country.</td>\n",
       "      <td>(5) Made the game much better</td>\n",
       "      <td>I like any customization and strategy</td>\n",
       "      <td>$50+ USD</td>\n",
       "      <td>In App Purchases (paying for exclusive content)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>245.355994</td>\n",
       "      <td>505.0</td>\n",
       "      <td></td>\n",
       "      <td>Cross Country Events</td>\n",
       "      <td>19</td>\n",
       "      <td>15.967313</td>\n",
       "      <td>4.156400</td>\n",
       "      <td>7.117190</td>\n",
       "      <td>-39.889538</td>\n",
       "      <td>Race Preferences: Flat vs. Cross-Country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HRC_survey_t3_2024_5</td>\n",
       "      <td>Sell a horse (because stable is maxed): view a...</td>\n",
       "      <td>(5) Made the game much better</td>\n",
       "      <td>I like any customization and strategy</td>\n",
       "      <td>$50+ USD</td>\n",
       "      <td>In App Purchases (paying for exclusive content)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>245.355994</td>\n",
       "      <td>505.0</td>\n",
       "      <td></td>\n",
       "      <td>Horse Selling and Stats View</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.321768</td>\n",
       "      <td>3.327364</td>\n",
       "      <td>26.394068</td>\n",
       "      <td>21.343136</td>\n",
       "      <td>Noise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 168 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T01:22:13.119736Z",
     "start_time": "2025-03-18T01:21:15.584091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "markdown_report = generate_cluster_report(df)\n",
    "\n",
    "# save the report as markdown\n",
    "output_path = os.path.join(root_dir, project, \"AI_report.md\")"
   ],
   "id": "2011a7bf3a21c035",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 14:21:15,584 - INFO - Generate AI summary for cluster Horse Training Time Frustration\n",
      "2025-03-18 14:21:20,133 - INFO - Total tokens used: 3581\n",
      "2025-03-18 14:21:20,133 - INFO - Generate AI summary for cluster Fun Factor and Enjoyment\n",
      "2025-03-18 14:21:23,011 - INFO - Total tokens used: 6166\n",
      "2025-03-18 14:21:23,013 - INFO - Generate AI summary for cluster Gold Earning Opportunities and Costs\n",
      "2025-03-18 14:21:25,053 - INFO - Total tokens used: 8793\n",
      "2025-03-18 14:21:25,053 - INFO - Generate AI summary for cluster Equestrian Sports and Disciplines\n",
      "2025-03-18 14:21:26,558 - INFO - Total tokens used: 11226\n",
      "2025-03-18 14:21:26,558 - INFO - Generate AI summary for cluster Enhanced Free Roam Experience\n",
      "2025-03-18 14:21:28,561 - INFO - Total tokens used: 13491\n",
      "2025-03-18 14:21:28,564 - INFO - Generate AI summary for cluster Equal Access for All Players\n",
      "2025-03-18 14:21:30,496 - INFO - Total tokens used: 15717\n",
      "2025-03-18 14:21:30,496 - INFO - Generate AI summary for cluster Horse Bonding and Care Activities\n",
      "2025-03-18 14:21:31,921 - INFO - Total tokens used: 17984\n",
      "2025-03-18 14:21:31,921 - INFO - Generate AI summary for cluster Winning Races and Horse Training\n",
      "2025-03-18 14:21:34,078 - INFO - Total tokens used: 20021\n",
      "2025-03-18 14:21:34,080 - INFO - Generate AI summary for cluster Foal Care Frustrations\n",
      "2025-03-18 14:21:35,884 - INFO - Total tokens used: 21821\n",
      "2025-03-18 14:21:35,890 - INFO - Generate AI summary for cluster Race Preferences: Flat vs. Cross-Country\n",
      "2025-03-18 14:21:37,292 - INFO - Total tokens used: 23212\n",
      "2025-03-18 14:21:37,304 - INFO - Generate AI summary for cluster More Horse Stalls Needed\n",
      "2025-03-18 14:21:38,481 - INFO - Total tokens used: 24678\n",
      "2025-03-18 14:21:38,481 - INFO - Generate AI summary for cluster Live Event Frustrations and Dislikes\n",
      "2025-03-18 14:21:39,947 - INFO - Total tokens used: 26118\n",
      "2025-03-18 14:21:39,947 - INFO - Generate AI summary for cluster Horse Breed Expansion Ideas\n",
      "2025-03-18 14:21:41,133 - INFO - Total tokens used: 27422\n",
      "2025-03-18 14:21:41,136 - INFO - Generate AI summary for cluster Tack Customization and Affordability\n",
      "2025-03-18 14:21:43,433 - INFO - Total tokens used: 28581\n",
      "2025-03-18 14:21:43,434 - INFO - Generate AI summary for cluster \"High Costs and Pay-to-Win\"\n",
      "2025-03-18 14:21:44,818 - INFO - Total tokens used: 29717\n",
      "2025-03-18 14:21:44,818 - INFO - Generate AI summary for cluster Story Goals Frustration and Discontent\n",
      "2025-03-18 14:21:46,429 - INFO - Total tokens used: 30809\n",
      "2025-03-18 14:21:46,429 - INFO - Generate AI summary for cluster Team Engagement Frustrations\n",
      "2025-03-18 14:21:48,007 - INFO - Total tokens used: 31800\n",
      "2025-03-18 14:21:48,007 - INFO - Generate AI summary for cluster Horse Racing Game Enthusiasm\n",
      "2025-03-18 14:21:49,544 - INFO - Total tokens used: 32850\n",
      "2025-03-18 14:21:49,547 - INFO - Generate AI summary for cluster Pasture Capacity and Management Issues\n",
      "2025-03-18 14:21:50,871 - INFO - Total tokens used: 33886\n",
      "2025-03-18 14:21:50,871 - INFO - Generate AI summary for cluster Discontent with Breeds and Traits\n",
      "2025-03-18 14:21:52,011 - INFO - Total tokens used: 34719\n",
      "2025-03-18 14:21:52,011 - INFO - Generate AI summary for cluster Event Hub Discontent and Confusion\n",
      "2025-03-18 14:21:53,732 - INFO - Total tokens used: 35543\n",
      "2025-03-18 14:21:53,732 - INFO - Generate AI summary for cluster Challenging Horse Breeding for Stats\n",
      "2025-03-18 14:21:55,792 - INFO - Total tokens used: 36568\n",
      "2025-03-18 14:21:55,792 - INFO - Generate AI summary for cluster Mobile Horse Customization Requests\n",
      "2025-03-18 14:21:57,430 - INFO - Total tokens used: 37479\n",
      "2025-03-18 14:21:57,430 - INFO - Generate AI summary for cluster Crossbreeding Preferences in Horses\n",
      "2025-03-18 14:21:59,086 - INFO - Total tokens used: 38327\n",
      "2025-03-18 14:21:59,086 - INFO - Generate AI summary for cluster Horse Pricing Controversy\n",
      "2025-03-18 14:22:00,698 - INFO - Total tokens used: 39272\n",
      "2025-03-18 14:22:00,698 - INFO - Generate AI summary for cluster Friendship-Based Horse Trading System\n",
      "2025-03-18 14:22:02,138 - INFO - Total tokens used: 40106\n",
      "2025-03-18 14:22:02,138 - INFO - Generate AI summary for cluster Affordable Horse Breeding Solutions\n",
      "2025-03-18 14:22:03,497 - INFO - Total tokens used: 40883\n",
      "2025-03-18 14:22:03,499 - INFO - Generate AI summary for cluster Event Accessibility Enhancements\n",
      "2025-03-18 14:22:04,878 - INFO - Total tokens used: 41619\n",
      "2025-03-18 14:22:04,878 - INFO - Generate AI summary for cluster Horse Coat Breeding and Collection\n",
      "2025-03-18 14:22:06,299 - INFO - Total tokens used: 42336\n",
      "2025-03-18 14:22:06,315 - INFO - Generate AI summary for cluster Frustrations of Coat Breeding\n",
      "2025-03-18 14:22:11,483 - INFO - Total tokens used: 43137\n",
      "2025-03-18 14:22:11,483 - INFO - Generate AI summary for cluster High Costs of Horse Breeding\n",
      "2025-03-18 14:22:13,101 - INFO - Total tokens used: 43873\n",
      "2025-03-18 14:22:13,113 - INFO - Markdown Report has been written.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d918487ab8389905"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T01:22:41.115473Z",
     "start_time": "2025-03-18T01:22:41.089184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save markdown report\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(markdown_report)\n"
   ],
   "id": "ea940c8b073d589e",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# AI Summary\n",
    "### Indivuaidual subPrompts"
   ],
   "id": "7338e1798411f35e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T20:52:50.196182400Z",
     "start_time": "2025-03-16T22:50:21.095109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from helper.prompt_templates import *\n",
    "from helper.utils import api_settings\n",
    "\n",
    "\n",
    "# Initialize global token counters\n",
    "prompt_tokens = 0\n",
    "completion_tokens = 0\n",
    "\n",
    "def track_tokens(response):\n",
    "    \"\"\"\n",
    "    Updates the global token counters based on the API response.\n",
    "\n",
    "    Args:\n",
    "        response: The API response containing token usage.\n",
    "    \"\"\"\n",
    "    global prompt_tokens, completion_tokens\n",
    "    prompt_tokens += response.usage.prompt_tokens\n",
    "    completion_tokens += response.usage.completion_tokens\n",
    "\n",
    "\n",
    "# Initialize logger\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Initialize global token counters\n",
    "prompt_tokens = 0\n",
    "completion_tokens = 0\n",
    "\n",
    "def track_tokens(response):\n",
    "    \"\"\"\n",
    "    Updates the global token counters based on the API response.\n",
    "    \"\"\"\n",
    "    global prompt_tokens, completion_tokens\n",
    "    prompt_tokens += response.usage.prompt_tokens\n",
    "    completion_tokens += response.usage.completion_tokens\n",
    "\n",
    "\n",
    "def generate_cluster_report(df: pd.DataFrame):\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # STEP 1: Build the \"hard facts\" table for each cluster\n",
    "    # ---------------------------------------------------\n",
    "    cluster_counts = (\n",
    "        df.groupby('hdbscan_id_name', dropna=False)['sentence']\n",
    "          .count()\n",
    "          .reset_index(name='total_data_points')\n",
    "    )\n",
    "\n",
    "    sentiment_counts = (\n",
    "        df.groupby(['hdbscan_id_name', 'sentiment'])['sentence']\n",
    "          .count()\n",
    "          .reset_index(name='count')\n",
    "    )\n",
    "\n",
    "    sentiment_pivot = (\n",
    "        sentiment_counts\n",
    "        .pivot_table(index='hdbscan_id_name',\n",
    "                     columns='sentiment',\n",
    "                     values='count',\n",
    "                     fill_value=0)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    cluster_summary_df = cluster_counts.merge(\n",
    "        sentiment_pivot,\n",
    "        on='hdbscan_id_name',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Exclude \"Noise\" if desired\n",
    "    cluster_summary_df = cluster_summary_df[cluster_summary_df['hdbscan_id_name'] != \"Noise\"]\n",
    "\n",
    "    rename_map = {}\n",
    "    for col in ['positive', 'negative', 'inconclusive']:\n",
    "        if col in cluster_summary_df.columns:\n",
    "            rename_map[col] = f\"{col}_count\"\n",
    "    cluster_summary_df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "    # Sort by total_data_points DESCENDING so the largest cluster is first\n",
    "    cluster_summary_df.sort_values(by='total_data_points', ascending=False, inplace=True)\n",
    "\n",
    "    logger.info(\"Data is structured, summarizing clusters...\")\n",
    "\n",
    "    markdown_report = \"# Cluster Report\\n\\n\"\n",
    "\n",
    "    cluster_to_statements = (\n",
    "        df.groupby('hdbscan_id_name')['sentence']\n",
    "          .apply(list)\n",
    "          .to_dict()\n",
    "    )\n",
    "\n",
    "    for _, row in cluster_summary_df.iterrows():\n",
    "        cluster_name = row['hdbscan_id_name']\n",
    "\n",
    "        total_points = int(row.get('total_data_points', 0))\n",
    "        positive_count = int(row.get('Positive', 0))\n",
    "        negative_count = int(row.get('Negative', 0))\n",
    "        inconclusive_count = int(row.get('Inconclusive', 0))\n",
    "\n",
    "        # ---------------------------------------------------\n",
    "        # Hard facts table\n",
    "        # ---------------------------------------------------\n",
    "        markdown_report += f\"## Cluster: {cluster_name}\\n\\n\"\n",
    "        markdown_report += \"### Hard Facts\\n\\n\"\n",
    "        sentiment_distribution = (f\"| Metric              | Value |\\n\"\n",
    "                                  f\"|---------------------|-------|\\n\"\n",
    "                                  f\"| **Total player statements**       | {total_points} |\\n\"\n",
    "                                  f\"| **Positive statements**          | {positive_count} |\\n\"\n",
    "                                  f\"| **Negative statements**          | {negative_count} |\\n\"\n",
    "                                  f\"| **Inconclusive statements**      | {inconclusive_count} |\\n\\n\")\n",
    "\n",
    "        markdown_report += sentiment_distribution\n",
    "\n",
    "\n",
    "        # ---------------------------------------------------\n",
    "        # Prepare statements text & define sub-prompts\n",
    "        # ---------------------------------------------------\n",
    "        statements_for_this_cluster = cluster_to_statements[cluster_name]\n",
    "        statements_text = \"\\n\".join(f\"- {s}\" for s in statements_for_this_cluster)\n",
    "\n",
    "        # Create each sub-prompt\n",
    "        prompt_short_summary = prompt_template_summary_short.format(\n",
    "            video_game=\"Into the Dead\",\n",
    "            cluster_name=cluster_name,\n",
    "            statements=statements_text\n",
    "        )\n",
    "\n",
    "        prompt_pain_points = prompt_template_pain_points.format(\n",
    "            video_game=\"Into the Dead\",\n",
    "            cluster_name=cluster_name,\n",
    "            statements=statements_text\n",
    "        )\n",
    "\n",
    "        prompt_highlights = prompt_template_highlights.format(\n",
    "            video_game=\"Into the Dead\",\n",
    "            cluster_name=cluster_name,\n",
    "            statements=statements_text\n",
    "        )\n",
    "\n",
    "        prompt_summary = prompt_template_summary.format(\n",
    "            video_game=\"Into the Dead\",\n",
    "            cluster_name=cluster_name,\n",
    "            statements=statements_text,\n",
    "            sentiment_distribution = sentiment_distribution\n",
    "        )\n",
    "\n",
    "        # ---------------------------------------------------\n",
    "        # Make the LLM calls\n",
    "        # ---------------------------------------------------\n",
    "        try:\n",
    "            # logger.info(f\"Generate short summary for cluster {cluster_name}\")\n",
    "            # response_short = api_settings[\"client\"].chat.completions.create(\n",
    "            #     model=api_settings[\"model\"],\n",
    "            #     messages=[\n",
    "            #         {\"role\": \"system\", \"content\": \"You are an expert summarizing user statements for a video game.\"},\n",
    "            #         {\"role\": \"user\", \"content\": prompt_short_summary},\n",
    "            #     ]\n",
    "            # )\n",
    "            # track_tokens(response_short)\n",
    "            # summary_short_text = response_short.choices[0].message.content.strip()\n",
    "\n",
    "            logger.info(f\"Generate AI summary for cluster {cluster_name}\")\n",
    "            response = api_settings[\"client\"].chat.completions.create(\n",
    "                model=api_settings[\"model\"],\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an expert summarizing user statements for a video game.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt_summary},\n",
    "                ]\n",
    "            )\n",
    "            track_tokens(response)\n",
    "            summary_text = response.choices[0].message.content.strip()\n",
    "            logger.info(f\"Total tokens used: {prompt_tokens + completion_tokens}\")\n",
    "\n",
    "            # logger.info(f\"Generate pain points for cluster {cluster_name}\")\n",
    "            # response_pain = api_settings[\"client\"].chat.completions.create(\n",
    "            #     model=api_settings[\"model\"],\n",
    "            #     messages=[\n",
    "            #         {\"role\": \"system\", \"content\": \"You are an expert summarizing user statements for a video game.\"},\n",
    "            #         {\"role\": \"user\", \"content\": prompt_pain_points},\n",
    "            #     ]\n",
    "            # )\n",
    "            # track_tokens(response_pain)\n",
    "            # pain_points_text = response_pain.choices[0].message.content.strip()\n",
    "            #\n",
    "            # logger.info(f\"Generate positive highlights for cluster {cluster_name}\")\n",
    "            # response_highlights = api_settings[\"client\"].chat.completions.create(\n",
    "            #     model=api_settings[\"model\"],\n",
    "            #     messages=[\n",
    "            #         {\"role\": \"system\", \"content\": \"You are an expert summarizing user statements for a video game.\"},\n",
    "            #         {\"role\": \"user\", \"content\": prompt_highlights},\n",
    "            #     ]\n",
    "            # )\n",
    "            # track_tokens(response_highlights)\n",
    "            # highlights_text = response_highlights.choices[0].message.content.strip()\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error summarizing cluster {cluster_name}: {e}\")\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "        # ---------------------------------------------------\n",
    "        # Append sub-sections to the Markdown\n",
    "        # ---------------------------------------------------\n",
    "        # markdown_report += \"### Brief\\n\\n\"\n",
    "        # markdown_report += summary_short_text + \"\\n\\n\"\n",
    "\n",
    "        markdown_report += \"### Summary\\n\\n\"\n",
    "        markdown_report += summary_text + \"\\n\\n\"\n",
    "\n",
    "        markdown_report += \"---\\n\\n\"\n",
    "\n",
    "    logger.info(\"Markdown Report has been generated.\")\n",
    "    return markdown_report\n",
    "\n"
   ],
   "id": "2f2b51a1cae8c1ee",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T20:52:50.266481700Z",
     "start_time": "2025-03-16T22:50:23.953132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_path = os.path.join(root_dir, project, \"db_final.json\")\n",
    "with open(input_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "df = pd.DataFrame(data)\n",
    "markdown_report = generate_cluster_report(df)\n",
    "\n",
    "# save the report as markdown\n",
    "output_path = os.path.join(root_dir, project, \"AI_report.md\")"
   ],
   "id": "eae35ff9f045e7a5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 11:50:24,032 - INFO - Data is structured, summarizing clusters...\n",
      "2025-03-17 11:50:24,032 - INFO - Generate AI summary for cluster Character Interactions and Relationships\n",
      "2025-03-17 11:50:29,253 - INFO - Total tokens used: 1116\n",
      "2025-03-17 11:50:29,261 - INFO - Generate AI summary for cluster Weapon Customization and Upgrades\n",
      "2025-03-17 11:50:36,481 - INFO - Total tokens used: 2021\n",
      "2025-03-17 11:50:36,481 - INFO - Generate AI summary for cluster Combat Evasion and Defense Mechanics\n",
      "2025-03-17 11:50:40,017 - INFO - Total tokens used: 2823\n",
      "2025-03-17 11:50:40,033 - INFO - Generate AI summary for cluster Loot Tracking Enhancements\n",
      "2025-03-17 11:50:46,568 - INFO - Total tokens used: 3910\n",
      "2025-03-17 11:50:46,568 - INFO - Generate AI summary for cluster Shelter Management and Expansion\n",
      "2025-03-17 11:50:52,913 - INFO - Total tokens used: 4929\n",
      "2025-03-17 11:50:52,913 - INFO - Generate AI summary for cluster Dynamic Randomization in Gameplay\n",
      "2025-03-17 11:50:57,237 - INFO - Total tokens used: 5725\n",
      "2025-03-17 11:50:57,237 - INFO - Generate AI summary for cluster Backpack and Inventory Expansion\n",
      "2025-03-17 11:51:01,797 - INFO - Total tokens used: 6557\n",
      "2025-03-17 11:51:01,797 - INFO - Generate AI summary for cluster Dynamic Task Management in Gameplay\n",
      "2025-03-17 11:51:05,516 - INFO - Total tokens used: 7359\n",
      "2025-03-17 11:51:05,532 - INFO - Generate AI summary for cluster Survivor Exploration and Scavenging Expansion\n",
      "2025-03-17 11:51:09,847 - INFO - Total tokens used: 8197\n",
      "2025-03-17 11:51:09,847 - INFO - Generate AI summary for cluster \"Enhanced Movement and Animation Quality\"\n",
      "2025-03-17 11:51:13,916 - INFO - Total tokens used: 8955\n",
      "2025-03-17 11:51:13,916 - INFO - Generate AI summary for cluster Character Customization Options\n",
      "2025-03-17 11:51:17,138 - INFO - Total tokens used: 9559\n",
      "2025-03-17 11:51:17,138 - INFO - Generate AI summary for cluster Enhanced Zombie Survival Strategies\n",
      "2025-03-17 11:51:21,735 - INFO - Total tokens used: 10304\n",
      "2025-03-17 11:51:21,735 - INFO - Generate AI summary for cluster Auto Weapon Management System\n",
      "2025-03-17 11:51:26,316 - INFO - Total tokens used: 11020\n",
      "2025-03-17 11:51:26,316 - INFO - Generate AI summary for cluster Improved Game Tutorials and Guides\n",
      "2025-03-17 11:51:30,654 - INFO - Total tokens used: 11677\n",
      "2025-03-17 11:51:30,657 - INFO - Generate AI summary for cluster Sound Awareness Indicators\n",
      "2025-03-17 11:51:34,418 - INFO - Total tokens used: 12355\n",
      "2025-03-17 11:51:34,418 - INFO - Generate AI summary for cluster Zombie Combat Evasion and Defense\n",
      "2025-03-17 11:51:37,616 - INFO - Total tokens used: 13127\n",
      "2025-03-17 11:51:37,620 - INFO - Generate AI summary for cluster Disappointing Survival Game Comparisons\n",
      "2025-03-17 11:51:42,207 - INFO - Total tokens used: 13895\n",
      "2025-03-17 11:51:42,207 - INFO - Generate AI summary for cluster Enhanced Game Saving Mechanisms\n",
      "2025-03-17 11:51:46,452 - INFO - Total tokens used: 14647\n",
      "2025-03-17 11:51:46,452 - INFO - Generate AI summary for cluster Survivor Dynamics and Narrative Depth\n",
      "2025-03-17 11:51:51,522 - INFO - Total tokens used: 15364\n",
      "2025-03-17 11:51:51,533 - INFO - Generate AI summary for cluster Game Save Functions and Options\n",
      "2025-03-17 11:51:55,778 - INFO - Total tokens used: 15765\n",
      "2025-03-17 11:51:55,794 - INFO - Generate AI summary for cluster Stealth Zombie Kill Mechanics\n",
      "2025-03-17 11:51:58,986 - INFO - Total tokens used: 16423\n",
      "2025-03-17 11:51:58,986 - INFO - Generate AI summary for cluster Game Difficulty Settings\n",
      "2025-03-17 11:52:02,314 - INFO - Total tokens used: 16903\n",
      "2025-03-17 11:52:02,314 - INFO - Markdown Report has been generated.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T20:52:50.270484400Z",
     "start_time": "2025-03-16T22:52:09.423554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save markdown report\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(markdown_report)"
   ],
   "id": "dc267b62b2886943",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Big Picture Summary",
   "id": "e8c3f0cd79b6b0a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T20:52:50.271484800Z",
     "start_time": "2025-03-17T03:41:24.193437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_big_picture_summary(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Produces a Markdown string with overall stats (time range, top clusters, etc.).\n",
    "    - Calculates top negative/positive clusters by **percentage**.\n",
    "    - Ensures total size is calculated correctly (excluding noise).\n",
    "    - Formats percentages to **one decimal place** with a `%` sign.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure timestamps are datetime (if not already)\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df['pp_timestamp']):\n",
    "        df['pp_timestamp'] = pd.to_datetime(df['pp_timestamp'], errors='coerce')\n",
    "\n",
    "    # Aggregate cluster data\n",
    "    cluster_counts = df.groupby('hdbscan_id_name', dropna=False)['sentence'].count().reset_index(name='total_data_points')\n",
    "\n",
    "    # Summaries of sentiment distribution\n",
    "    sentiment_counts = df.groupby(['hdbscan_id_name', 'sentiment'])['sentence'].count().reset_index(name='count')\n",
    "    pivot_sent = (\n",
    "        sentiment_counts\n",
    "        .pivot_table(index='hdbscan_id_name', columns='sentiment', values='count', fill_value=0)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    cluster_summary_df = cluster_counts.merge(pivot_sent, on='hdbscan_id_name', how='left')\n",
    "\n",
    "\n",
    "    # Convert numeric columns to int\n",
    "    for col in ['total_data_points', 'Positive', 'Negative', 'Inconclusive']:\n",
    "        if col in cluster_summary_df.columns:\n",
    "            cluster_summary_df[col] = cluster_summary_df[col].astype(int, errors='ignore')\n",
    "\n",
    "\n",
    "\n",
    "    # Compute sentiment percentages, rounded to one decimal place\n",
    "    cluster_summary_df['negative_percentage'] = (\n",
    "        cluster_summary_df['Negative'] / cluster_summary_df['total_data_points'] * 100\n",
    "    ).fillna(0).round(1)\n",
    "\n",
    "    cluster_summary_df['positive_percentage'] = (\n",
    "        cluster_summary_df['Positive'] / cluster_summary_df['total_data_points'] * 100\n",
    "    ).fillna(0).round(1)\n",
    "\n",
    "    # 2) Count requests\n",
    "    request_df = (\n",
    "        df[df['category'] == 'request']\n",
    "        .groupby('hdbscan_id_name')['sentence']\n",
    "        .count()\n",
    "        .reset_index(name='request_count')\n",
    "    )\n",
    "    cluster_summary_df = cluster_summary_df.merge(request_df, on='hdbscan_id_name', how='left')\n",
    "    cluster_summary_df['request_count'] = cluster_summary_df['request_count'].fillna(0).astype(int)\n",
    "\n",
    "    # Exclude Noise for ranking\n",
    "    non_noise_df = cluster_summary_df[cluster_summary_df['hdbscan_id_name'] != \"Noise\"]\n",
    "\n",
    "    # Identify Noise Cluster Size\n",
    "    noise_count = cluster_summary_df.loc[cluster_summary_df['hdbscan_id_name'] == \"Noise\", 'total_data_points'].values[0] if \"Noise\" in cluster_summary_df['hdbscan_id_name'].values else 0\n",
    "\n",
    "    # Top clusters sorted by **percentage** sentiment\n",
    "    top_3_neg = non_noise_df.sort_values(by='negative_percentage', ascending=False).head(5)\n",
    "    top_3_pos = non_noise_df.sort_values(by='positive_percentage', ascending=False).head(5)\n",
    "\n",
    "    top_3_req = non_noise_df.sort_values(by='request_count', ascending=False).head(5)\n",
    "    top_5_overall = non_noise_df.sort_values(by='total_data_points', ascending=False).head(5)\n",
    "\n",
    "    # Convert tables to Markdown string format\n",
    "    def table_to_md(table_df, columns, percentage_cols=None):\n",
    "        \"\"\"\n",
    "        Converts a DataFrame into a Markdown table.\n",
    "        - Rounds and adds a `%` sign to specified percentage columns.\n",
    "        \"\"\"\n",
    "        md_table = \"| \" + \" | \".join(columns) + \" |\\n\"\n",
    "        md_table += \"|-\" + \"-|-\".join([\"-\" * len(col) for col in columns]) + \"-|\\n\"\n",
    "        for _, row in table_df.iterrows():\n",
    "            row_values = []\n",
    "            for col in columns:\n",
    "                if percentage_cols and col in percentage_cols:\n",
    "                    row_values.append(f\"{row[col]:.1f}%\")  # Format percentage with one decimal\n",
    "                else:\n",
    "                    row_values.append(f\"{row[col]}\")\n",
    "            md_table += \"| \" + \" | \".join(row_values) + \" |\\n\"\n",
    "        return md_table\n",
    "\n",
    "    # Markdown generation\n",
    "    markdown_report = \"# Big Picture Report\\n\\n\"\n",
    "\n",
    "    # General Stats\n",
    "    markdown_report += f\" **Data Source:** {project}\\n\\n\"\n",
    "    markdown_report += f\" **Time Range:** {df['pp_timestamp'].min()} **-** {df['pp_timestamp'].max()}\\n\\n\"\n",
    "    markdown_report += f\" **Total Statements:** {len(df)}, Noise: {noise_count}\\n\\n\"\n",
    "\n",
    "    # Top 5 Negative Clusters**\n",
    "    markdown_report += \"### Top 5 Negative Clusters \\n\\n\"\n",
    "    markdown_report += table_to_md(top_3_neg, ['hdbscan_id_name', 'negative_percentage'], percentage_cols=['negative_percentage']) + \"\\n\\n\"\n",
    "\n",
    "    # Top 5 Positive Clusters**\n",
    "    markdown_report += \"### Top 5 Positive Clusters \\n\\n\"\n",
    "    markdown_report += table_to_md(top_3_pos, ['hdbscan_id_name', 'positive_percentage'], percentage_cols=['positive_percentage']) + \"\\n\\n\"\n",
    "\n",
    "    # Top 5 request clusters\n",
    "    markdown_report += \"### Top 5 Request Clusters \\n\\n\"\n",
    "    markdown_report += table_to_md(top_3_req, ['hdbscan_id_name', 'request_count']) + \"\\n\\n\"\n",
    "\n",
    "    # Top 5 clusters overall\n",
    "    markdown_report += \"### Top 5 Clusters\\n\\n\"\n",
    "    markdown_report += table_to_md(top_5_overall, ['hdbscan_id_name', 'total_data_points']) + \"\\n\\n\"\n",
    "\n",
    "    logger.info(\"Big Picture has been generated.\")\n",
    "\n",
    "    return markdown_report\n"
   ],
   "id": "75bd65238238fff7",
   "outputs": [],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T20:52:50.271484800Z",
     "start_time": "2025-03-17T03:41:26.829040Z"
    }
   },
   "cell_type": "code",
   "source": "test = generate_big_picture_summary(df)",
   "id": "de624551d97d49a6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 16:41:26,837 - INFO - Big Picture has been generated.\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T20:52:50.320653400Z",
     "start_time": "2025-03-17T03:41:28.205753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_path = os.path.join(root_dir, project, \"BigPicture_report.md\")\n",
    "# save markdown report\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(test)"
   ],
   "id": "cee9d642eb00395d",
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Big Picture with LLM",
   "id": "dfff94c8e9204837"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:30:07.496999Z",
     "start_time": "2025-03-18T00:30:07.301740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import openai\n",
    "import os\n",
    "import logging\n",
    "from dotenv import dotenv_values\n",
    "import json\n",
    "\n",
    "from helper.utils import configure_api\n",
    "d = dotenv_values()\n",
    "for k in d.keys():\n",
    "    os.environ[k] = d[k]\n",
    "\n",
    "# General modules\n",
    "\n",
    "# Setup API keys\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_key = openai_api_key\n",
    "client = openai.Client()\n",
    "\n",
    "# Specify models\n",
    "chat_model_name = 'gpt-4o-mini'\n",
    "openai_embedding_model = \"text-embedding-3-small\"\n",
    "local_embedding_model = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "configure_api(client, chat_model_name)\n",
    "\n",
    "# Specify paths for storing (backup) data\n",
    "root_dir = r'S:\\SID\\Analytics\\Working Files\\Individual\\Florian\\Projects\\DataScience\\cluster_analysis\\Data\\Backup'\n",
    "data_source = 'DRS_Next_Fest'\n",
    "\n",
    "# Setup the logger\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.getLogger(\"httpx\").setLevel(logging.ERROR)      # Supress API HTTP request logs"
   ],
   "id": "9beaf5ada5413e32",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:30:12.322236Z",
     "start_time": "2025-03-18T00:30:12.293419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import random\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Global token counters for demonstration\n",
    "prompt_tokens = 0\n",
    "completion_tokens = 0\n",
    "\n",
    "def track_tokens(response):\n",
    "    \"\"\"\n",
    "    Updates the global token counters based on the API response.\n",
    "    \"\"\"\n",
    "    global prompt_tokens, completion_tokens\n",
    "    prompt_tokens += response.usage.prompt_tokens\n",
    "    completion_tokens += response.usage.completion_tokens\n",
    "\n",
    "def generate_big_picture_summary_with_llm(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Produces a Markdown string with overall stats tables AND\n",
    "    a single LLM-based summary for the top N clusters in each category,\n",
    "    using your existing prompt framework and api_settings for the OpenAI client.\n",
    "\n",
    "    Unlike before, we do *not* summarize each cluster individually.\n",
    "    Instead, we gather all statements from the top 5 clusters of each category,\n",
    "    then produce a single summary per category.\n",
    "    \"\"\"\n",
    "\n",
    "    from helper.prompt_templates import prompt_template_top5\n",
    "    from helper.utils import api_settings\n",
    "\n",
    "    # Ensure timestamps are datetime (if not already)\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df['pp_timestamp']):\n",
    "        df['pp_timestamp'] = pd.to_datetime(df['pp_timestamp'], errors='coerce')\n",
    "\n",
    "    # --- 1) Aggregate cluster data ---\n",
    "    cluster_counts = (\n",
    "        df.groupby('hdbscan_id_name', dropna=False)['sentence']\n",
    "          .count()\n",
    "          .reset_index(name='total_data_points')\n",
    "    )\n",
    "\n",
    "    # --- 2) Summaries of sentiment distribution ---\n",
    "    sentiment_counts = (\n",
    "        df.groupby(['hdbscan_id_name', 'sentiment'])['sentence']\n",
    "          .count()\n",
    "          .reset_index(name='count')\n",
    "    )\n",
    "    pivot_sent = (\n",
    "        sentiment_counts\n",
    "        .pivot_table(index='hdbscan_id_name', columns='sentiment',\n",
    "                     values='count', fill_value=0)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    cluster_summary_df = cluster_counts.merge(pivot_sent, on='hdbscan_id_name', how='left')\n",
    "\n",
    "    # Convert numeric columns to int\n",
    "    for col in ['total_data_points', 'Positive', 'Negative', 'Inconclusive']:\n",
    "        if col in cluster_summary_df.columns:\n",
    "            cluster_summary_df[col] = cluster_summary_df[col].fillna(0).astype(int)\n",
    "\n",
    "    # Compute sentiment percentages\n",
    "    cluster_summary_df['negative_percentage'] = (\n",
    "        cluster_summary_df['Negative'] / cluster_summary_df['total_data_points'] * 100\n",
    "    ).fillna(0).round(1)\n",
    "\n",
    "    cluster_summary_df['positive_percentage'] = (\n",
    "        cluster_summary_df['Positive'] / cluster_summary_df['total_data_points'] * 100\n",
    "    ).fillna(0).round(1)\n",
    "\n",
    "    # Count requests\n",
    "    request_df = (\n",
    "        df[df['category'] == 'request']\n",
    "        .groupby('hdbscan_id_name')['sentence']\n",
    "        .count()\n",
    "        .reset_index(name='request_count')\n",
    "    )\n",
    "    cluster_summary_df = cluster_summary_df.merge(request_df, on='hdbscan_id_name', how='left')\n",
    "    cluster_summary_df['request_count'] = cluster_summary_df['request_count'].fillna(0).astype(int)\n",
    "\n",
    "    # Exclude Noise for ranking\n",
    "    non_noise_df = cluster_summary_df[cluster_summary_df['hdbscan_id_name'] != \"Noise\"]\n",
    "\n",
    "    # Identify Noise Cluster Size\n",
    "    noise_count = 0\n",
    "    if \"Noise\" in cluster_summary_df['hdbscan_id_name'].values:\n",
    "        noise_count = cluster_summary_df.loc[\n",
    "            cluster_summary_df['hdbscan_id_name'] == \"Noise\", 'total_data_points'\n",
    "        ].values[0]\n",
    "\n",
    "    # --- 3) Select top clusters to display in tables ---\n",
    "    top_5_neg = non_noise_df.sort_values(by='negative_percentage', ascending=False).head(5)\n",
    "    top_5_pos = non_noise_df.sort_values(by='positive_percentage', ascending=False).head(5)\n",
    "    top_5_req = non_noise_df.sort_values(by='request_count', ascending=False).head(5)\n",
    "    top_5_overall = non_noise_df.sort_values(by='total_data_points', ascending=False).head(5)\n",
    "\n",
    "    # --- Helper: Convert DataFrame to Markdown ---\n",
    "    def table_to_md(table_df, columns, percentage_cols=None):\n",
    "        \"\"\"\n",
    "        Converts a DataFrame into a Markdown table.\n",
    "        - Rounds and adds a '%' sign to specified percentage columns.\n",
    "        \"\"\"\n",
    "        md_table = \"| \" + \" | \".join(columns) + \" |\\n\"\n",
    "        md_table += \"|-\" + \"-|-\".join([\"-\" * len(col) for col in columns]) + \"-|\\n\"\n",
    "        for _, row in table_df.iterrows():\n",
    "            row_values = []\n",
    "            for col in columns:\n",
    "                if percentage_cols and col in percentage_cols:\n",
    "                    row_values.append(f\"{row[col]:.1f}%\")\n",
    "                else:\n",
    "                    row_values.append(f\"{row[col]}\")\n",
    "            md_table += \"| \" + \" | \".join(row_values) + \" |\\n\"\n",
    "        return md_table\n",
    "\n",
    "    # --- 4) Summarize top clusters in a single prompt ---\n",
    "\n",
    "    def summarize_topN_clusters(\n",
    "        df: pd.DataFrame,\n",
    "        top_df: pd.DataFrame,\n",
    "        cluster_group: str,\n",
    "        sentiment: str\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Gathers ALL statements from the top 'N' clusters in top_df.\n",
    "        If there are more than 150 statements, randomly sample 150.\n",
    "        Then calls the LLM *once* to summarize them all together.\n",
    "        \"\"\"\n",
    "\n",
    "        from helper.prompt_templates import prompt_template_top5\n",
    "        from helper.utils import api_settings\n",
    "\n",
    "        # 1) Collect all cluster names\n",
    "        top_cluster_names = top_df['hdbscan_id_name'].unique().tolist()\n",
    "\n",
    "        # 2) Gather all statements from these clusters\n",
    "        mask = df['hdbscan_id_name'].isin(top_cluster_names)\n",
    "        selected_statements = df.loc[mask, 'sentence'].tolist()\n",
    "\n",
    "        # 3) If more than 150, randomly sample\n",
    "        if len(selected_statements) > 150:\n",
    "            logger.info(f\"More than 150 statements in the cluster group {cluster_group}. Sampling 150.\")\n",
    "            selected_statements = random.sample(selected_statements, 150)\n",
    "        else:\n",
    "            logger.info(f\"{cluster_group} has {len(selected_statements)} player statements. Continuing...\")\n",
    "\n",
    "        # 4) Build the prompt text\n",
    "        statements_text = \"\\n\".join(f\"- {s}\" for s in selected_statements)\n",
    "\n",
    "        # 5) Format the prompt\n",
    "        prompt_topic = prompt_template_top5.format(\n",
    "            video_game=\"Into the Dead\",\n",
    "            cluster_group=cluster_group,\n",
    "            sentiment=sentiment,\n",
    "            statements=statements_text\n",
    "        )\n",
    "\n",
    "        logger.info(f\"Generate AI summary for top 5 {cluster_group} clusters.\")\n",
    "        try:\n",
    "            response = api_settings[\"client\"].chat.completions.create(\n",
    "                model=api_settings[\"model\"],\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You are an expert summarizing user statements for a video game.\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt_topic\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            track_tokens(response)\n",
    "            summary_text = response.choices[0].message.content.strip()\n",
    "            logger.info(f\"Tokens used so far: {prompt_tokens + completion_tokens}\")\n",
    "            return summary_text\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error summarizing top {cluster_group}: {e}\")\n",
    "            return f\"Error summarizing top {cluster_group} clusters: {e}\"\n",
    "\n",
    "    # --- 5) Construct the Markdown Report ---\n",
    "    markdown_report = \"# Big Picture Report\\n\\n\"\n",
    "    markdown_report += f\"**Data Source:** {data_source}\\n\\n\"\n",
    "    markdown_report += f\"**Time Range:** {df['pp_timestamp'].min()} - {df['pp_timestamp'].max()}\\n\\n\"\n",
    "    markdown_report += f\"**Total Statements:** {len(df)}, Noise: {noise_count}\\n\\n\"\n",
    "\n",
    "    # -- 5a) Top 5 Negative Clusters\n",
    "    markdown_report += \"### Top 5 Negative Clusters\\n\\n\"\n",
    "    markdown_report += table_to_md(\n",
    "        top_5_neg,\n",
    "        ['hdbscan_id_name', 'negative_percentage'],\n",
    "        percentage_cols=['negative_percentage']\n",
    "    ) + \"\\n\\n\"\n",
    "\n",
    "    neg_summary = summarize_topN_clusters(\n",
    "        df,\n",
    "        top_5_neg,\n",
    "        cluster_group=\"Negative\",\n",
    "        sentiment=\"negative\"\n",
    "    )\n",
    "    markdown_report += f\"**Summary for Top 5 Negative Clusters:**\\n{neg_summary}\\n\\n\"\n",
    "\n",
    "    # -- 5b) Top 5 Positive Clusters\n",
    "    markdown_report += \"### Top 5 Positive Clusters\\n\\n\"\n",
    "    markdown_report += table_to_md(\n",
    "        top_5_pos,\n",
    "        ['hdbscan_id_name', 'positive_percentage'],\n",
    "        percentage_cols=['positive_percentage']\n",
    "    ) + \"\\n\\n\"\n",
    "\n",
    "    pos_summary = summarize_topN_clusters(\n",
    "        df,\n",
    "        top_5_pos,\n",
    "        cluster_group=\"Positive\",\n",
    "        sentiment=\"positive\"\n",
    "    )\n",
    "    markdown_report += f\"**Summary for Top 5 Positive Clusters:**\\n{pos_summary}\\n\\n\"\n",
    "\n",
    "    # -- 5c) Top 5 Request Clusters\n",
    "    markdown_report += \"### Top 5 Request Clusters\\n\\n\"\n",
    "    markdown_report += table_to_md(\n",
    "        top_5_req,\n",
    "        ['hdbscan_id_name', 'request_count']\n",
    "    ) + \"\\n\\n\"\n",
    "\n",
    "    req_summary = summarize_topN_clusters(\n",
    "        df,\n",
    "        top_5_req,\n",
    "        cluster_group=\"Request\",\n",
    "        sentiment=\"wishes or requests\"\n",
    "    )\n",
    "    markdown_report += f\"**Summary for Top 5 Request Clusters:**\\n{req_summary}\\n\\n\"\n",
    "\n",
    "    # -- 5d) Top 5 Clusters Overall\n",
    "    markdown_report += \"### Top 5 Clusters (Overall)\\n\\n\"\n",
    "    markdown_report += table_to_md(top_5_overall, ['hdbscan_id_name', 'total_data_points']) + \"\\n\\n\"\n",
    "\n",
    "    overall_summary = summarize_topN_clusters(\n",
    "        df,\n",
    "        top_5_overall,\n",
    "        cluster_group=\"biggest\",\n",
    "        sentiment=\"largest\"\n",
    "    )\n",
    "    markdown_report += f\"**Summary for Top 5 Overall Largest Clusters:**\\n{overall_summary}\\n\\n\"\n",
    "\n",
    "    logger.info(\"Big Picture + LLM Summaries have been generated.\")\n",
    "    return markdown_report\n"
   ],
   "id": "82f801a63d128d77",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:30:28.718821Z",
     "start_time": "2025-03-18T00:30:22.815709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_path = os.path.join(root_dir, data_source, \"db_final.json\")\n",
    "with open(input_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "df = pd.DataFrame(data)\n",
    "markdown_report = generate_big_picture_summary_with_llm(df)"
   ],
   "id": "2d1ee697de1b621f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 13:30:22,966 - INFO - Negative has 135 player statements. Continuing...\n",
      "2025-03-18 13:30:22,966 - INFO - Generate AI summary for top 5 Negative clusters.\n",
      "2025-03-18 13:30:24,477 - INFO - Tokens used so far: 2439\n",
      "2025-03-18 13:30:24,477 - INFO - Positive has 143 player statements. Continuing...\n",
      "2025-03-18 13:30:24,479 - INFO - Generate AI summary for top 5 Positive clusters.\n",
      "2025-03-18 13:30:25,641 - INFO - Tokens used so far: 4470\n",
      "2025-03-18 13:30:25,647 - INFO - More than 150 statements in the cluster group Request. Sampling 150.\n",
      "2025-03-18 13:30:25,647 - INFO - Generate AI summary for top 5 Request clusters.\n",
      "2025-03-18 13:30:27,121 - INFO - Tokens used so far: 7214\n",
      "2025-03-18 13:30:27,136 - INFO - More than 150 statements in the cluster group biggest. Sampling 150.\n",
      "2025-03-18 13:30:27,141 - INFO - Generate AI summary for top 5 biggest clusters.\n",
      "2025-03-18 13:30:28,712 - INFO - Tokens used so far: 10020\n",
      "2025-03-18 13:30:28,712 - INFO - Big Picture + LLM Summaries have been generated.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T00:30:39.688399Z",
     "start_time": "2025-03-18T00:30:39.662815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save the report as markdown\n",
    "output_path = os.path.join(root_dir, data_source, \"Big_picture_summary.md\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(markdown_report)"
   ],
   "id": "93a62414fc972dd7",
   "outputs": [],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
